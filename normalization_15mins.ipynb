{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abde2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.subplots as sp\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import json\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import tensorflow as tfs\n",
    "\n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "import datetime\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to database\n",
    "bucket = \"rp_one_m\"\n",
    "\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", token=\"6nJJG2EUP8hGm0gsbi-TXScDIiMCMl03TMleXQ2gr4m9l5EO1XMGa97D0tmUebQyGOEo_fR_vsbwZrNpucVcMQ==\", org=\"thesis\")\n",
    "\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "query_api = client.query_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0700eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the id for the database\n",
    "#7847f5f7\n",
    "#45b46fef\n",
    "#15ecc075\n",
    "#ee9f3d22\n",
    "baseId = \"7847f5f7\"\n",
    "battery_id = baseId + \"-battery\"\n",
    "inverter_id = baseId + \"-inverter\"\n",
    "grid_id = baseId + \"-grid\"\n",
    "battery2grid_id = baseId + \"-battery2grid\"\n",
    "    \n",
    "print(battery_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef35b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query the database for the data\n",
    "\n",
    "#query for solarInverterMetrics\n",
    "tables_inverter = query_api.query(f'''\n",
    "from(bucket: \"rp_one_m\")\n",
    "  |> range(start: 2018-01-01T00:00:01Z, stop: 2024-11-18T23:30:00Z)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"solarInverterMetrics\")\n",
    "  |> filter(fn: (r) => r[\"nodeId\"] == \"{inverter_id}\")\n",
    "  |> pivot(\n",
    "      rowKey:[\"_time\"], \n",
    "      columnKey:[\"_field\"], \n",
    "      valueColumn:\"_value\"\n",
    "  )\n",
    "  |> sort(columns: [\"_time\"])  //sort by timestamp''')\n",
    "\n",
    "#query for submeteringMetrics\n",
    "tables_submetering = query_api.query(f'''\n",
    "from(bucket: \"rp_one_m\")\n",
    "  |> range(start: 2018-01-01T00:00:01Z, stop: 2024-11-18T23:30:00Z)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"submeteringMetrics\")\n",
    "  |> filter(fn: (r) => r[\"nodeId\"] == \"{grid_id}\")\n",
    "  |> pivot(\n",
    "      rowKey:[\"_time\"], \n",
    "      columnKey:[\"_field\"], \n",
    "      valueColumn:\"_value\"\n",
    "  )\n",
    "  |> sort(columns: [\"_time\"])  //sort by timestamp''')\n",
    "\n",
    "#query for batteryMetrics\n",
    "tables_battery = query_api.query(f'''\n",
    "from(bucket: \"rp_one_m\")\n",
    "  |> range(start: 2018-01-01T00:00:01Z, stop: 2024-11-18T23:30:00Z)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"batteryMetrics\")\n",
    "  |> filter(fn: (r) => r[\"nodeId\"] == \"{battery_id}\")\n",
    "  |> pivot(\n",
    "      rowKey:[\"_time\"], \n",
    "      columnKey:[\"_field\"], \n",
    "      valueColumn:\"_value\"\n",
    "  )\n",
    "  |> sort(columns: [\"_time\"])  //sort by timestamp''')\n",
    "\n",
    "#query for battery2grid\n",
    "tables_battery2grid = query_api.query(f'''\n",
    "from(bucket: \"rp_one_m\")\n",
    "  |> range(start: 2018-01-01T00:00:01Z, stop: 2024-11-18T23:30:00Z)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"submeteringMetrics\")\n",
    "  |> filter(fn: (r) => r[\"nodeId\"] == \"{battery2grid_id}\")\n",
    "  |> pivot(\n",
    "      rowKey:[\"_time\"], \n",
    "      columnKey:[\"_field\"], \n",
    "      valueColumn:\"_value\"\n",
    "  )\n",
    "  |> sort(columns: [\"_time\"])  //sort by timestamp''')\n",
    "\n",
    "#convert query results to DataFrame for each measurement\n",
    "data_inverter = []\n",
    "data_submetering = []\n",
    "data_battery = []\n",
    "data_battery2grid = []\n",
    "\n",
    "#process inverter data\n",
    "for table in tables_inverter:\n",
    "    for row in table.records:\n",
    "        data_inverter.append(row.values)\n",
    "df_inverter = pd.DataFrame(data_inverter)\n",
    "\n",
    "#process submetering data\n",
    "for table in tables_submetering:\n",
    "    for row in table.records:\n",
    "        data_submetering.append(row.values)\n",
    "df_submetering = pd.DataFrame(data_submetering)\n",
    "\n",
    "#process battery data\n",
    "for table in tables_battery:\n",
    "    for row in table.records:\n",
    "        data_battery.append(row.values)\n",
    "df_battery = pd.DataFrame(data_battery)\n",
    "\n",
    "#process battery2grid data\n",
    "for table in tables_battery2grid:\n",
    "    for row in table.records:\n",
    "        data_battery2grid.append(row.values)\n",
    "df_battery2grid = pd.DataFrame(data_battery2grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give subscripts\n",
    "df_inverter = df_inverter.rename(columns=lambda x: x + '_inverter')\n",
    "df_submetering = df_submetering.rename(columns=lambda x: x + '_submetering')\n",
    "df_battery = df_battery.rename(columns=lambda x: x + '_battery')\n",
    "df_battery2grid = df_battery2grid.rename(columns=lambda x: x + '_battery2grid')\n",
    "#put _time back to normal\n",
    "df_inverter.rename(columns={'_time_inverter':'_time'}, inplace=True)\n",
    "df_submetering.rename(columns={'_time_submetering':'_time'}, inplace=True)\n",
    "df_battery.rename(columns={'_time_battery':'_time'}, inplace=True)\n",
    "df_battery2grid.rename(columns={'_time_battery2grid':'_time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all dataframes on _time column\n",
    "#indicator: Adds a column to the output dataFrame called _merge that shows which dataFrame each row originated from.\n",
    "df_combined = pd.merge(df_inverter, df_submetering, on='_time', how='outer', suffixes=('_inverter', '_submetering'), indicator='Origin_1_2')\n",
    "df_combined = pd.merge(df_combined, df_battery, on='_time', how='outer', suffixes=('', '_battery'), indicator='Origin_1_2_3')\n",
    "df_combined = pd.merge(df_combined, df_battery2grid, on='_time', how='outer', suffixes=('', '_battery2grid'), indicator='Origin_1_2_3_4')\n",
    "\n",
    "#check if all have same time columns\n",
    "if(df_combined['Origin_1_2'].equals(df_combined['Origin_1_2_3']) and df_combined['Origin_1_2_3'].equals(df_combined['Origin_1_2_3_4'])):\n",
    "    print(\"all have same timestamps\")\n",
    "    df_combined.drop(columns=['Origin_1_2', 'Origin_1_2_3', 'Origin_1_2_3_4'], inplace=True)\n",
    "else:\n",
    "    print(\"not all have same timestamps\")\n",
    "\n",
    "#drop columns with suffixes for _start and _stop\n",
    "columns_to_drop = [col for col in df_combined.columns if col.startswith('_start') or col.startswith('_stop')]\n",
    "df_combined.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "#keep only one _start and _stop column from the first dataframe (inverter)\n",
    "df_combined['_start'] = df_inverter['_start_inverter']\n",
    "df_combined['_stop'] = df_inverter['_stop_inverter']\n",
    "\n",
    "#display the first 10 rows of the combined dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_combined.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all unnecessary\n",
    "nodeID = df_combined['nodeId_battery'][0]\n",
    "startTime = df_combined['_time'][0]\n",
    "endTime = df_combined['_time'].iloc[-1]\n",
    "df_combined.drop(columns=['result_inverter', 'nodeId_inverter', 'result_submetering', 'nodeId_submetering', 'result_battery',\n",
    "                          '_measurement_battery', 'result_battery2grid', '_measurement_battery2grid', 'nodeId_battery2grid',\n",
    "                         'table_inverter', 'table_submetering', 'table_battery', 'table_battery2grid',\n",
    "                         '_measurement_inverter', '_measurement_submetering', 'nodeId_battery'], inplace=True)\n",
    "#drop deltas, not relevant since meeting 27112024\n",
    "df_combined.drop(columns=['sum_producedEnergyDeltaTot_Wh_inverter', 'sum_exportedEnergyDeltaTot_Wh_submetering',\n",
    "                         'sum_importedEnergyDeltaTot_Wh_submetering', 'sum_chargedEnergyDeltaTot_Wh_battery',\n",
    "                         'sum_dischargedEnergyDeltaTot_Wh_battery', 'sum_exportedEnergyDeltaTot_Wh_battery2grid',\n",
    "                         'sum_importedEnergyDeltaTot_Wh_battery2grid'], inplace=True)\n",
    "df_combined.drop(columns=['_start', '_stop'], inplace=True)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2e569",
   "metadata": {},
   "source": [
    "# drop bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33555149",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = go.Figure()\n",
    "\n",
    "initial.add_trace(go.Scatter(x=df_combined[\"_time\"], y=df_combined[\"mean_actualPowerTot_W_inverter\"], mode='lines', name='transformation 2'))\n",
    "\n",
    "# Update layout for better visualization\n",
    "initial.update_layout(\n",
    "    title='initial data',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "initial.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd33c51",
   "metadata": {},
   "source": [
    "# ee9f3d22\n",
    "df_combined.drop(df_combined[df_combined['_time'] <= \"2021-05-12 00:00:00+00:00\"].index, inplace = True)\n",
    "df_inverterPower = df_combined[['_time', 'mean_actualPowerTot_W_inverter']]\n",
    "df_inverterPower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93c848",
   "metadata": {},
   "source": [
    "# 15ecc075\n",
    "df_combined.drop(df_combined[df_combined['_time'] <= \"2021-08-12 00:00:00+00:00\"].index, inplace = True)\n",
    "df_inverterPower = df_combined[['_time', 'mean_actualPowerTot_W_inverter']]\n",
    "df_inverterPower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626f9af",
   "metadata": {},
   "source": [
    "# 45b46fef\n",
    "df_combined.drop(df_combined[df_combined['_time'] <= \"2021-05-5 00:00:00+00:00\"].index, inplace = True)\n",
    "df_inverterPower = df_combined[['_time', 'mean_actualPowerTot_W_inverter']]\n",
    "df_inverterPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d526962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7847f5f7\n",
    "df_combined.drop(df_combined[(df_combined['_time'] >= '2020-01-21 06:20:00+00:00') & (df_combined['_time'] < '2021-02-10 06:24:00+00:00')].index,\n",
    "                inplace = True)\n",
    "\n",
    "df_combined.drop(df_combined[df_combined['_time'] < '2021-02-11 11:32:00+00:00'].index, inplace = True)\n",
    "\n",
    "# 0033d164\n",
    "#df_combined.drop(df_combined[df_combined['_time'] < '2021-09-17 00:00:00+00:00'].index, inplace = True)\n",
    "\n",
    "df_inverterPower = df_combined[['_time', 'mean_actualPowerTot_W_inverter']]\n",
    "df_inverterPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc87250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the households file with lats and longs + only the ids that are in the database\n",
    "#json files\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\households_in_database.json\"\n",
    "#read JSON into a dataFrame\n",
    "df_households = pd.read_json(file_path)\n",
    "\n",
    "df_households.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f07aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = df_households[df_households['id'] == baseId]['city'].values[0]\n",
    "print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cdf104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new DataFrame with a complete range of 1-minute intervals\n",
    "full_time_range = pd.date_range(start=df_inverterPower['_time'].min(), end=df_inverterPower['_time'].max(), freq='1min')\n",
    "df_full_range = pd.DataFrame(full_time_range, columns=['_time'])\n",
    "\n",
    "#merge the original DataFrame with the full range DataFrame\n",
    "df_merged = pd.merge(df_full_range, df_inverterPower, on='_time', how='left')\n",
    "\n",
    "#convert the DataFrame to appropriate dtypes\n",
    "df_merged = df_merged.infer_objects()\n",
    "\n",
    "#for interpolation make sure that production is zero when sun is not up\n",
    "df_merged.set_index('_time', inplace=True)\n",
    "city = LocationInfo(city, \"Belgium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796c694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pytz #ensure timezone consistency\n",
    "def get_sunrise_sunset(date):\n",
    "    s = sun(city.observer, date=date)\n",
    "    return s['sunrise'].astimezone(pytz.timezone(city.timezone)), s['sunset'].astimezone(pytz.timezone(city.timezone))\n",
    "\n",
    "df_merged['date'] = df_merged.index.date\n",
    "sun_times = {date: get_sunrise_sunset(date) for date in df_merged['date'].unique()}\n",
    "\n",
    "#vectorized operation: fix inconsistencies in dataframe due to resampling\n",
    "for date, (sunrise, sunset) in sun_times.items():\n",
    "    #from midnight to sunrise\n",
    "    mask_before_sunrise = (df_merged.index >= pd.Timestamp(date, tz='Europe/Brussels')) & (df_merged.index < sunrise)\n",
    "    #from sunset till midnight\n",
    "    mask_after_sunset = (df_merged.index > sunset) & (df_merged.index < pd.Timestamp(date, tz='Europe/Brussels') + pd.Timedelta(days=1))\n",
    "    \n",
    "    df_merged.loc[mask_before_sunrise, 'mean_actualPowerTot_W_inverter'] = 0\n",
    "    df_merged.loc[mask_after_sunset, 'mean_actualPowerTot_W_inverter'] = 0\n",
    "\n",
    "df_merged.drop(columns=['date'], inplace=True)\n",
    "\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dbba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolate the missing values\n",
    "df_inverterPower_interpolated = df_merged.interpolate(method='linear')\n",
    "df_inverterPower_interpolated['mean_actualPowerTot_W_inverter'] = df_inverterPower_interpolated['mean_actualPowerTot_W_inverter'].round(1)\n",
    "\n",
    "#print the interpolated DataFrame\n",
    "print(\"Interpolated DataFrame:\")\n",
    "df_inverterPower_interpolated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dddc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_inverterPower_interpolated.copy()\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fed94",
   "metadata": {},
   "source": [
    "file_path = \"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\inverter_power_data_7847f5f7.csv\"\n",
    "\n",
    "df_data.to_csv(file_path)\n",
    "#df_data.to_csv('inverter_power_data_0033d164.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b250d3f2",
   "metadata": {},
   "source": [
    "#comment when running whole file\n",
    "\n",
    "#7847f5f7\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\inverter_power_data_7847f5f7.csv\"\n",
    "\n",
    "df_data = pd.read_csv(file_path, index_col='_time', parse_dates=True)\n",
    "\n",
    "#df_data = pd.read_csv('inverter_power_data_0033d164.csv', index_col='_time', parse_dates=True)\n",
    "\n",
    "df_data.index = df_data.index.tz_convert('Europe/Brussels')\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47384ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_data.index, y=df_data['mean_actualPowerTot_W_inverter'], mode='lines', name='Power'))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title='Inverter Power Over Time',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    #xaxis_rangeslider_visible=True,\n",
    "    margin=dict(t=150),  # Increase top margin to fit legend and title\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # horizontal layout\n",
    "        y=1,           # place it above the plot area\n",
    "        x=0.5,\n",
    "        xanchor='center',\n",
    "        yanchor='bottom'\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray',\n",
    "        range=['2021-05-07 00:00:00', '2021-05-07 23:59:59']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a543c905",
   "metadata": {},
   "source": [
    "# drop the beginning where there is no data\n",
    "\n",
    "\n",
    "#7847f5f7\n",
    "\n",
    "df_data = df_data[df_data.index >= '2021-03-11']\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7edc0e",
   "metadata": {},
   "source": [
    "# downsample to 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsampling needs to be before the normalisation\n",
    "\n",
    "df_data = df_data.resample(rule = '15min', closed='left', label='right').mean()\n",
    "df_data = df_data.round()\n",
    "\n",
    "nan_rows = df_data[df_data['mean_actualPowerTot_W_inverter'].isna()]\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ef669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[df_data[\"mean_actualPowerTot_W_inverter\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab09268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.index = pd.to_datetime(df_data.index)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_data.index, y=df_data['mean_actualPowerTot_W_inverter'], mode='lines', name='Power'))\n",
    "\n",
    "#update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title='Inverter Power Over Time',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr_day(series, k=1.5):\n",
    "    \"\"\"\n",
    "    Compute Q1, Q3, and IQR for the given series and replace values outside\n",
    "    [Q1 - k*IQR, Q3 + k*IQR] with NaN.\n",
    "    \"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - k * IQR\n",
    "    upper_bound = Q3 + k * IQR\n",
    "    return series.where((series >= lower_bound) & (series <= upper_bound), np.nan)\n",
    "\n",
    "def fill_outliers_with_moving_avg(series, window=5):\n",
    "    \"\"\"\n",
    "    Replace NaN values in the series (i.e. outliers) with the moving average\n",
    "    of the previous 'window' timesteps. (Uses shift(1) to ensure only previous values are used.)\n",
    "    \"\"\"\n",
    "    rolling_avg = series.shift(1).rolling(window=window, min_periods=1).mean()\n",
    "    return series.fillna(rolling_avg)\n",
    "\n",
    "def process_day_production(series, k=1.5, window=5):\n",
    "    \"\"\"\n",
    "    For a day's series:\n",
    "      - Identify the production period: from the first nonzero to the last nonzero value.\n",
    "      - Apply IQR outlier filtering to that period.\n",
    "      - Replace outliers (NaNs) with the moving average of the previous 'window' values.\n",
    "    The rest of the day (typically night when production is 0) remains unchanged.\n",
    "    \"\"\"\n",
    "    #identify production time where production > 0\n",
    "    production_mask = series > 0\n",
    "    if production_mask.sum() == 0:\n",
    "        #if there is no production at all, return the series as is.\n",
    "        return series\n",
    "\n",
    "    #get the timestamps where production occurs\n",
    "    production_times = series[production_mask].index\n",
    "    first_time = production_times[0]\n",
    "    last_time = production_times[-1]\n",
    "    \n",
    "    #extract the production period\n",
    "    production_series = series.loc[first_time:last_time]\n",
    "    \n",
    "    #remove outliers using IQR for this subset\n",
    "    production_clean = remove_outliers_iqr_day(production_series, k=k)\n",
    "    \n",
    "    #replace the outliers with a moving average of the previous 'window' values\n",
    "    production_filled = fill_outliers_with_moving_avg(production_clean, window=window)\n",
    "    \n",
    "    #update the original series for this day with the cleaned production period\n",
    "    series.loc[first_time:last_time] = production_filled\n",
    "    return series\n",
    "\n",
    "#now apply this function day-by-day\n",
    "df_filtered_day = df_data.copy()\n",
    "\n",
    "df_filtered_day['mean_actualPowerTot_W_inverter'] = df_filtered_day.groupby(\n",
    "pd.Grouper(freq='D')\n",
    ")['mean_actualPowerTot_W_inverter'].transform(\n",
    "    lambda s: process_day_production(s, k=1.5, window=5)\n",
    ")\n",
    "\n",
    "#if there are nan's at the beginning of the day\n",
    "df_filtered_day['mean_actualPowerTot_W_inverter'] = df_filtered_day['mean_actualPowerTot_W_inverter'].ffill()\n",
    "\n",
    "df_filtered_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b0bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_data.index, y=df_data['mean_actualPowerTot_W_inverter'], mode='lines', name='Power_original'))\n",
    "fig.add_trace(go.Scatter(x=df_filtered_day.index, y=df_filtered_day['mean_actualPowerTot_W_inverter'], mode='lines', name='Power'))\n",
    "\n",
    "#update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title='Inverter Power Over Time',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "#show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82586b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_filtered_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7504f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pmax(t) profile\n",
    "df_data.index = pd.to_datetime(df_data.index)\n",
    "\n",
    "#extract the time of day\n",
    "df_data['time_of_day'] = df_data.index.time\n",
    "\n",
    "# group by the time of day and calculate the maximum value\n",
    "#max_profile = df_data.groupby('time_of_day')['mean_actualPowerTot_W_inverter'].quantile(0.95)\n",
    "max_profile = df_data.groupby('time_of_day')['mean_actualPowerTot_W_inverter'].max()\n",
    "df_data = df_data.drop(columns=['time_of_day'])\n",
    "max_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_profile = pd.DataFrame(max_profile)\n",
    "df_max_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed168a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = go.Figure()\n",
    "\n",
    "fig3.add_trace(go.Scatter(x=max_profile.index, y=max_profile.values, mode='lines', name='Power'))\n",
    "\n",
    "#update layout for better visualization\n",
    "fig3.update_layout(\n",
    "    title='max profile',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ad3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation 1 for Pmax: Savitzky-golay filter\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "#The Savitzky-Golay filter applies a least-squares polynomial fit over a moving window.\n",
    "#To maintain symmetry, the filter must have an equal number of points on both sides of the center point.\n",
    "window_size = 31 #41\n",
    "poly_order = 3 #3\n",
    "smoothed_profile = savgol_filter(max_profile, window_length=window_size, polyorder=poly_order, mode='nearest')\n",
    "\n",
    "#convert back to a Pandas Series\n",
    "smoothed_profile = pd.Series(smoothed_profile, index=max_profile.index)\n",
    "\n",
    "#set any values below zero to zero\n",
    "smoothed_profile[smoothed_profile < 0] = 0\n",
    "\n",
    "step1 = go.Figure()\n",
    "\n",
    "step1.add_trace(go.Scatter(x=max_profile.index, y=max_profile.values, mode='lines', name='original'))\n",
    "step1.add_trace(go.Scatter(x=smoothed_profile.index, y=smoothed_profile.values, mode='lines', name='step1'))\n",
    "\n",
    "#update layout for better visualization\n",
    "step1.update_layout(\n",
    "    title='max profile step1',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "step1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1999af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation 2: adjust for seasonal variations\n",
    "\n",
    "#In summer, the daylight hours are longer, so the power curve should be stretched.\n",
    "#In winter, the daylight hours are shorter, so the power curve should be squeezed.\n",
    "\n",
    "#use first and last non-zero production times as sunrise and sunset\n",
    "import pytz #ensure timezone consistency\n",
    "city = LocationInfo(\"Brussels\", \"Belgium\")\n",
    "\n",
    "#ensure datetime index\n",
    "df_data.index = pd.to_datetime(df_data.index)\n",
    "\n",
    "#group by each day and find T_start and T_end separately\n",
    "#changed to use the actual sunrise and sunset to prevent weird behavior on cloudy days\n",
    "def find_sun_times(day):\n",
    "    date = day.index[0].date()\n",
    "    s = sun(city.observer, date=date)\n",
    "    return pd.Series({\n",
    "        \"T_start\": s['sunrise'].astimezone(pytz.timezone(city.timezone)).time().replace(microsecond = 0),  #first nonzero time\n",
    "        \"T_end\": s['sunset'].astimezone(pytz.timezone(city.timezone)).time().replace(microsecond = 0)  #last nonzero time\n",
    "    })\n",
    "\n",
    "#apply function per day\n",
    "daily_sun_times = df_data.groupby(df_data.index.date).apply(find_sun_times)\n",
    "\n",
    "#reset index to keep dates\n",
    "daily_sun_times.reset_index(inplace=True)\n",
    "\n",
    "print(daily_sun_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feead98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next in transformation 2, stretch and squeze\n",
    "\n",
    "#convert smoothed_profile to dataFrame for easy manipulation\n",
    "df_smoothed_profile = smoothed_profile.reset_index()\n",
    "df_smoothed_profile.columns = [\"time_of_day\", \"P_max\"]\n",
    "\n",
    "#convert time_of_day to minutes since midnight for easier calculations\n",
    "df_smoothed_profile[\"minutes_since_midnight\"] = df_smoothed_profile[\"time_of_day\"].apply(lambda x: x.hour * 60 + x.minute)\n",
    "\n",
    "df_smoothed_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.index.date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "non_zero_profile = df_smoothed_profile[df_smoothed_profile[\"P_max\"] > 0]\n",
    "T_start_profile = non_zero_profile[\"time_of_day\"].min()\n",
    "T_end_profile = non_zero_profile[\"time_of_day\"].max()\n",
    "print(\"T_start_profile: \", T_start_profile)\n",
    "print(\"T_end_profile: \", T_end_profile)\n",
    "print(\" \")\n",
    "\n",
    "#daylength profile\n",
    "T_start_profile_min = T_start_profile.hour * 60 + T_start_profile.minute\n",
    "T_end_profile_min = T_end_profile.hour * 60 + T_end_profile.minute\n",
    "daylength_profile = T_end_profile_min - T_start_profile_min + 1 #inclusive\n",
    "print(\"daylength profile: \", daylength_profile)\n",
    "\n",
    "profile_data = df_smoothed_profile.iloc[T_start_profile_min // 15:T_end_profile_min // 15 + 1]\n",
    "print(profile_data)\n",
    "\n",
    "def adjust_pmax_2(day):\n",
    "    print(\"day\")\n",
    "    print(day)\n",
    "    date = day[\"index\"]\n",
    "    \n",
    "    #start of day according to sunrise and sunset per definition\n",
    "    \n",
    "    #T_start_day = day[\"T_start\"].iloc[0] #convert the value in the column to just the value\n",
    "    #T_end_day = day[\"T_end\"].iloc[0]\n",
    "    print(\"date: \", date)\n",
    "    \n",
    "    #start of day according to sunrise and sunset per first non zero value\n",
    "    non_zero_profile_day = df_data[(df_data.index.date == date.iloc[0]) & (df_data[\"mean_actualPowerTot_W_inverter\"] > 0)]\n",
    "    if not non_zero_profile_day.empty:\n",
    "        T_start_day = non_zero_profile_day.index.min()\n",
    "        T_end_day = non_zero_profile_day.index.max()\n",
    "    else: #take the one per definition\n",
    "        T_start_day = day[\"T_start\"].iloc[0] #convert the value in the column to just the value\n",
    "        T_end_day = day[\"T_end\"].iloc[0]\n",
    "    \n",
    "    print(\"T_start_day: \", T_start_day)\n",
    "    print(\"T_end_day: \", T_end_day)\n",
    "    \n",
    "    #calculate daylength day\n",
    "    T_start_day_min = T_start_day.hour * 60 + T_start_day.minute\n",
    "    T_end_day_min = T_end_day.hour * 60 + T_end_day.minute\n",
    "    daylength_day = T_end_day_min - T_start_day_min + 1 #inclusive\n",
    "    print(\"daylength day: \", daylength_day)\n",
    "    \n",
    "    #factor: need to put daylength_profile amount of values in daylength_day spaces\n",
    "    ratio = daylength_day/daylength_profile\n",
    "    \n",
    "    #generate original and new time indices\n",
    "    original_time = np.linspace(0, daylength_day, daylength_profile // 15 + 1)\n",
    "    new_time = np.linspace(0, daylength_day, daylength_day // 15 + 1)\n",
    "\n",
    "    \n",
    "    #interpolate the profile data\n",
    "    interpolator = interp1d(original_time, profile_data[\"P_max\"], kind='linear')\n",
    "    adjusted_profile = interpolator(new_time)\n",
    "    \n",
    "    #we have new P_max values --> new dataframe    \n",
    "    zero_padding_before = np.zeros(max(0, T_start_day_min // 15))\n",
    "    zero_padding_after = np.zeros(max(0, df_smoothed_profile.shape[0] - (T_end_day_min // 15)))\n",
    "\n",
    "\n",
    "    print(\"zero_padding_before: \", len(zero_padding_before))\n",
    "    print(\"zero_padding_after: \", len(zero_padding_after))\n",
    "    \n",
    "    final_profile = np.concatenate([zero_padding_before, adjusted_profile, zero_padding_after])\n",
    "    final_time = np.linspace(0, daylength_day, len(final_profile))\n",
    "    \n",
    "    adjusted_df = pd.DataFrame({\n",
    "        #\"time\": final_time,\n",
    "        \"P_max\": final_profile\n",
    "    })\n",
    "    print(adjusted_df)\n",
    "    \n",
    "    return adjusted_df\n",
    "    \n",
    "full_adjusted_df = pd.DataFrame()\n",
    "\n",
    "for date in daily_sun_times[\"index\"]:\n",
    "    adjusted_profile_df = adjust_pmax_2(daily_sun_times[daily_sun_times[\"index\"] == date])\n",
    "    \n",
    "    adjusted_profile_df[\"hours\"] = (adjusted_profile_df.index * 15) // 60\n",
    "    adjusted_profile_df[\"minutes\"] = (adjusted_profile_df.index * 15) % 60\n",
    "\n",
    "    \n",
    "    date_datetime = datetime.strptime(str(date), \"%Y-%m-%d\")  \n",
    "    \n",
    "    adjusted_profile_df[\"time\"] = adjusted_profile_df.apply(\n",
    "        lambda row: date_datetime + timedelta(hours=row[\"hours\"], minutes=row[\"minutes\"]), axis=1\n",
    "    )\n",
    "    adjusted_profile_df = adjusted_profile_df.drop(columns=[\"hours\", \"minutes\"])\n",
    "    \n",
    "    full_adjusted_df = pd.concat([full_adjusted_df, adjusted_profile_df], ignore_index=True)\n",
    "    #break\n",
    "    \n",
    "full_adjusted_df.set_index(\"time\", inplace=True)\n",
    "\n",
    "print(full_adjusted_df.head())\n",
    "\n",
    "step2_1 = go.Figure()\n",
    "\n",
    "step2_1.add_trace(go.Scatter(x=adjusted_profile_df.index, y=adjusted_profile_df[\"P_max\"], mode='lines', name='adjusted'))\n",
    "#step2_1.add_trace(go.Scatter(x=df_smoothed_profile.index, y=df_smoothed_profile[\"P_max\"], mode='lines', name='step1'))\n",
    "\n",
    "#update layout for better visualization\n",
    "step2_1.update_layout(\n",
    "    title='max profile step2_1',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "step2_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376686c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation 2\n",
    "#section_transformed_df = full_adjusted_df[full_adjusted_df.index <= '2021-08-11 00:00:00']\n",
    "\n",
    "section_transformed_df = full_adjusted_df\n",
    "\n",
    "step2_2 = go.Figure()\n",
    "\n",
    "step2_2.add_trace(go.Scatter(x=section_transformed_df.index, y=section_transformed_df[\"P_max\"], mode='lines', name='transformation 2'))\n",
    "#step2_1.add_trace(go.Scatter(x=df_smoothed_profile.index, y=df_smoothed_profile[\"P_max\"], mode='lines', name='step1'))\n",
    "\n",
    "#update layout for better visualization\n",
    "step2_2.update_layout(\n",
    "    title='max profile transformation 2',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "step2_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvlib\n",
    "import elevation\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Latitude and longitude of the location\n",
    "latitude = df_households.loc[df_households[\"id\"] == baseId, \"latitude\"].iloc[0]\n",
    "longitude = df_households.loc[df_households[\"id\"] == baseId, \"longitude\"].iloc[0]\n",
    "\n",
    "print(pvlib.location.lookup_altitude(latitude, longitude))\n",
    "#for now default to 10m\n",
    "\n",
    "#altitude = 10\n",
    "\n",
    "altitude = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation 3: GHI\n",
    "# use clearsky ineichen\n",
    "\n",
    "location = pvlib.location.Location(latitude, longitude, altitude=altitude)\n",
    "\n",
    "#convert the index to a pandas datetime index with UTC timezone\n",
    "times = pd.DatetimeIndex(full_adjusted_df.index, tz='UTC')\n",
    "\n",
    "#get clearsky data for all timestamps at once\n",
    "clearsky_data = location.get_clearsky(times)\n",
    "\n",
    "#extract the GHI values and assign them to the dataframe in one go\n",
    "full_adjusted_df['clearsky_ghi'] = clearsky_data['ghi'].values\n",
    "\n",
    "full_adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ghi_overall = full_adjusted_df['clearsky_ghi'].max()\n",
    "\n",
    "full_adjusted_df['date'] = full_adjusted_df.index.date\n",
    "daily_max_ghi = full_adjusted_df.groupby('date')['clearsky_ghi'].max()\n",
    "\n",
    "daily_max_ghi_ratio = daily_max_ghi / max_ghi_overall\n",
    "\n",
    "full_adjusted_df['daily_max_ghi_ratio'] = full_adjusted_df['date'].map(daily_max_ghi_ratio)\n",
    "\n",
    "full_adjusted_df['adjusted_P_max'] = full_adjusted_df['P_max'] * full_adjusted_df['daily_max_ghi_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feeb0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_adjusted_df = full_adjusted_df.drop(columns = [\"clearsky_ghi\", \"date\"])\n",
    "full_adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb317fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation 3\n",
    "#section_transformed_df = full_adjusted_df[full_adjusted_df.index <= '2021-08-11 00:00:00']\n",
    "\n",
    "section_transformed_df = full_adjusted_df\n",
    "\n",
    "\n",
    "step2_3 = go.Figure()\n",
    "\n",
    "step2_3.add_trace(go.Scatter(x=section_transformed_df.index, y=section_transformed_df[\"P_max\"], mode='lines', name='transformation 2'))\n",
    "step2_3.add_trace(go.Scatter(x=section_transformed_df.index, y=section_transformed_df[\"adjusted_P_max\"], mode='lines', name='transformation 3'))\n",
    "\n",
    "#update layout for better visualization\n",
    "step2_3.update_layout(\n",
    "    title='max profile transformation 3',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "step2_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91688d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41715df5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#try to fix that ideal profile is always bigger than actual profile\n",
    "\n",
    "df_data['date'] = df_data.index.date\n",
    "full_adjusted_df['date'] = full_adjusted_df.index.date\n",
    "\n",
    "#create a copy of adjusted_P_max to modify\n",
    "full_adjusted_df['scaled_adjusted_P_max'] = full_adjusted_df['adjusted_P_max']\n",
    "\n",
    "#get all unique dates\n",
    "unique_dates = df_data['date'].unique()\n",
    "\n",
    "for day in unique_dates:\n",
    "    #get data for the day\n",
    "    actual_day = df_data[df_data['date'] == day]\n",
    "    adjusted_day = full_adjusted_df[full_adjusted_df['date'] == day]\n",
    "\n",
    "    #get max values for that day\n",
    "    max_actual = actual_day['mean_actualPowerTot_W_inverter'].max()\n",
    "    max_adjusted = adjusted_day['adjusted_P_max'].max()\n",
    "\n",
    "    if max_adjusted < max_actual:\n",
    "        scale_factor = max_actual / max_adjusted\n",
    "        print(f\"Scaling {day}: {scale_factor:.2f}\")\n",
    "        \n",
    "        #apply scaling for that day's adjusted profile\n",
    "        day_mask = full_adjusted_df['date'] == day\n",
    "        full_adjusted_df.loc[day_mask, 'scaled_adjusted_P_max'] = full_adjusted_df.loc[day_mask, 'scaled_adjusted_P_max'] * scale_factor\n",
    "\n",
    "\n",
    "full_adjusted_df.drop(columns=['date'], inplace=True)\n",
    "df_data.drop(columns=['date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all transformations done\n",
    "#now normalize data with normalization profile\n",
    "\n",
    "df_data.index = df_data.index.tz_localize(None)  # Remove any timezone if present\n",
    "full_adjusted_df.index = full_adjusted_df.index.tz_localize(None)  # Remove any timezone if present\n",
    "\n",
    "#merge the two DataFrames on the 'time' index\n",
    "df_merged = df_data.merge(full_adjusted_df[['scaled_adjusted_P_max']], left_index=True, right_index=True, how='left')\n",
    "\n",
    "df_merged.index.name = '_time'\n",
    "#lose some data from full_adjusted_df near end since the df_data doesn't have full last day\n",
    "\n",
    "#check for missing values (NaN) in adjusted_P_max\n",
    "if df_merged['scaled_adjusted_P_max'].isna().any():\n",
    "    print(\"Warning: Some values are missing in the normalization profile.\")\n",
    "    \n",
    "#normalize the 'mean_actualPowerTot_W_inverter' column by dividing by the 'adjusted_P_max' column\n",
    "#df_merged['normalized_value'] = df_merged['mean_actualPowerTot_W_inverter'] / df_merged['adjusted_P_max']\n",
    "df_merged['normalized_value'] = np.where(\n",
    "    (df_merged['mean_actualPowerTot_W_inverter'] == 0) | (df_merged['scaled_adjusted_P_max'] == 0),\n",
    "    np.nan,  #set to NaN if either value is 0\n",
    "    df_merged['mean_actualPowerTot_W_inverter'] / df_merged['scaled_adjusted_P_max']  # Perform division otherwise\n",
    ")\n",
    "\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c004262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['scaled_adjusted_P_max']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210351a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb997e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325ecd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fix the nan at night\n",
    "df_merged['normalized_value'] = df_merged['normalized_value'].clip(upper=1)\n",
    "\n",
    "#assign a 'night'-variable for NaN values\n",
    "df_merged['night'] = df_merged['normalized_value'].isna().astype(int)\n",
    "\n",
    "df_merged_transform = df_merged.copy(deep = True)\n",
    "\n",
    "#initialize the first night\n",
    "firstNight = True\n",
    "firstSun = True\n",
    "sumValue = 0\n",
    "count = 0\n",
    "average = 0\n",
    "first_sunrise = 0\n",
    "\n",
    "for _, row in df_merged_transform.iterrows():\n",
    "    if (row['night'] == 1) & (firstNight):\n",
    "        #skip first night\n",
    "        continue\n",
    "    firstNight = False\n",
    "    if firstSun:\n",
    "        first_sunrise = row.index\n",
    "        firstSun = False\n",
    "    #start of first day\n",
    "    if row['night'] == 0:\n",
    "        sumValue += row['normalized_value']\n",
    "        count += 1\n",
    "        continue\n",
    "    else:\n",
    "        #summed all day values\n",
    "        average = sumValue / count\n",
    "        print('average: ', average)\n",
    "        break\n",
    "        \n",
    "firstNight = True\n",
    "for idx, row in df_merged_transform.iterrows():\n",
    "    if row['night'] == 1 & firstNight:\n",
    "        df_merged_transform.loc[idx, 'normalized_value'] = average\n",
    "        continue\n",
    "    firstNight = False\n",
    "    break\n",
    "\n",
    "#for the remaining nights\n",
    "sum_prev_night = []\n",
    "average_prev_day = 0\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for idx, row in df_merged_transform.iterrows():\n",
    "    if(pd.notna(row['normalized_value'])):\n",
    "        sum_prev_night.append(row['normalized_value'])\n",
    "    else:\n",
    "        #reset sum array after average calculation, once\n",
    "        if sum_prev_night:\n",
    "            average_prev_day = sum(sum_prev_night)/ len(sum_prev_night)\n",
    "            sum_prev_night = []\n",
    "            \n",
    "        df_merged_transform.at[idx, 'normalized_value'] = average_prev_day\n",
    "    \n",
    "    if counter % 1000 == 0:\n",
    "        print(f\"Processing row {counter}\")\n",
    "    counter += 1\n",
    "\n",
    "#df_merged_transform_rest = df_merged_transform\n",
    "print(first_sunrise)\n",
    "\n",
    "df_merged_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform done:\n",
    "df_merged = df_merged_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e354d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized dataset\n",
    "#section_normalized_df = df_merged[df_merged.index <= '2021-08-11 00:00:00']\n",
    "section_normalized_df = df_merged\n",
    "\n",
    "step3 = go.Figure()\n",
    "\n",
    "#step3.add_trace(go.Scatter(x=section_normalized_df.index, y=section_normalized_df[\"adjusted_P_max\"]/1000, mode='lines', name='transformation 3 original'))\n",
    "step3.add_trace(go.Scatter(x=section_normalized_df.index, y=section_normalized_df[\"scaled_adjusted_P_max\"]/1000, mode='lines', name='clear-sky profile'))\n",
    "#step3.add_trace(go.Scatter(x=section_normalized_df.index, y=section_normalized_df[\"normalized_value\"], mode='lines', name='normalized'))\n",
    "#step3.add_trace(go.Scatter(x=section_normalized_df.index, y=section_normalized_df[\"mean_actualPowerTot_W_inverter\"]/1000, mode='lines', name='actual production'))\n",
    "\n",
    "\n",
    "step3.update_layout(\n",
    "    title='normalized profile',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (kW)',\n",
    "    showlegend=True,\n",
    "    #xaxis_rangeslider_visible=True,\n",
    "    margin=dict(t=150),  # Increase top margin to fit legend and title\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # horizontal layout\n",
    "        y=1,           # place it above the plot area\n",
    "        x=0.5,\n",
    "        xanchor='center',\n",
    "        yanchor='bottom'\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray',\n",
    "        range=['2022-05-05', '2022-05-8']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "step3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca510c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary\n",
    "# normalized dataset\n",
    "#section_normalized_df = df_merged[df_merged.index <= '2021-08-11 00:00:00']\n",
    "section_normalized_df = df_merged\n",
    "\n",
    "step3 = go.Figure()\n",
    "\n",
    "#step3.add_trace(go.Scatter(x=section_normalized_df.index, y=section_normalized_df[\"adjusted_P_max\"]/1000, mode='lines', name='transformation 3 original'))\n",
    "step3.add_trace(go.Scatter(x=section_normalized_df.index, y=section_normalized_df[\"scaled_adjusted_P_max\"]/1000, mode='lines', name='clear-sky profile'))\n",
    "#step3.add_trace(go.Scatter(x=section_normalized_df.index, y=section_normalized_df[\"normalized_value\"], mode='lines', name='normalized'))\n",
    "#step3.add_trace(go.Scatter(x=section_normalized_df.index, y=section_normalized_df[\"mean_actualPowerTot_W_inverter\"]/1000, mode='lines', name='actual production'))\n",
    "\n",
    "\n",
    "step3.update_layout(\n",
    "    title='clear-sky profile',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (kW)',\n",
    "    xaxis_rangeslider_visible=True,\n",
    "    margin=dict(t=150),  # Increase top margin to fit legend and title\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # horizontal layout\n",
    "        y=1,           # place it above the plot area\n",
    "        x=0.5,\n",
    "        xanchor='center',\n",
    "        yanchor='bottom'\n",
    "    ),\n",
    "    showlegend=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "step3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['adjusted_P_max'] = df_merged['scaled_adjusted_P_max']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2538b",
   "metadata": {},
   "source": [
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\inverter_power_data_ee9f3d22_normalised_15min.csv\"\n",
    "\n",
    "df_merged.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct\n",
    "df_test = df_merged.copy()\n",
    "df_test[\"denormalized_value\"] = df_test[\"normalized_value\"]*df_test[\"scaled_adjusted_P_max\"]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a518c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalized dataset\n",
    "denormalized = go.Figure()\n",
    "\n",
    "denormalized.add_trace(go.Scatter(x=df_test.index, y=df_test[\"scaled_adjusted_P_max\"]/1000, mode='lines', name='transformation 3 scaled'))\n",
    "denormalized.add_trace(go.Scatter(x=df_test.index, y=df_test[\"adjusted_P_max\"]/1000, mode='lines', name='transformation 3'))\n",
    "denormalized.add_trace(go.Scatter(x=df_test.index, y=df_test[\"denormalized_value\"]/1000, mode='lines', name='denormalized'))\n",
    "denormalized.add_trace(go.Scatter(x=df_test.index, y=df_test[\"normalized_value\"], mode='lines', name='normalized'))\n",
    "denormalized.add_trace(go.Scatter(x=df_test.index, y=df_test[\"mean_actualPowerTot_W_inverter\"]/1000, mode='lines', name='mean_actualPowerTot_W_inverter'))\n",
    "\n",
    "\n",
    "# Update layout for better visualization\n",
    "denormalized.update_layout(\n",
    "    title='denormalized',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (kW)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "denormalized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "r2 = r2_score(df_test[\"mean_actualPowerTot_W_inverter\"], df_test[\"denormalized_value\"])\n",
    "print(\"R²-score: \", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

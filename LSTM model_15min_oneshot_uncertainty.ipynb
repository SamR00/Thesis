{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979155a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.subplots as sp\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import json\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import tensorflow as tfs\n",
    "\n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense, Lambda\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the households file with lats and longs + only the ids that are in the database\n",
    "#json files\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\households_in_database.json\"\n",
    "#read JSON into a dataFrame\n",
    "df_households = pd.read_json(file_path)\n",
    "\n",
    "df_households.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd9a030",
   "metadata": {},
   "source": [
    "# Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\aws_10min.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, index_col='timestamp', parse_dates=True)\n",
    "cutoff_timestamp = \"2022-06-19 04:20:00\"\n",
    "\n",
    "df = df.loc[:cutoff_timestamp]\n",
    "\n",
    "#part 2\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\aws_10min_rest.csv\"\n",
    "\n",
    "df2 = pd.read_csv(file_path, index_col='timestamp', parse_dates=True)\n",
    "cutoff_timestamp = \"2022-06-19 04:30:00\"\n",
    "\n",
    "df2 = df2.loc[cutoff_timestamp:]\n",
    "\n",
    "#combine them\n",
    "df_combined = pd.concat([df, df2])\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d17f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#haversine formula to compute the great-circle distance between two points\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # earth radius in km\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c  #distance in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f676b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_stations = df_combined.drop_duplicates(subset=\"code\", keep=\"first\")\n",
    "df_unique_stations[['lat', 'lon']] = df_unique_stations['the_geom'].str.extract(r'POINT \\(([^ ]+) ([^ ]+)\\)').astype(float)\n",
    "\n",
    "df_unique_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af59b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get lat and long of the household and calculate distance to the meteostations\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "household_id = \"7847f5f7\"\n",
    "row = df_households[df_households[\"id\"] == household_id]\n",
    "lat = row[\"latitude\"]\n",
    "lon = row[\"longitude\"]\n",
    "\n",
    "df_unique_stations['distance_km'] = df_unique_stations.apply(lambda row: haversine(lat, lon, row['lat'], row['lon']), axis=1)\n",
    "df_unique_stations = df_unique_stations.sort_values(\"distance_km\")\n",
    "df_unique_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8389f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ece41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec4cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the ghi values of the database\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\meteoStationsDatabaseData.csv\"\n",
    "\n",
    "meteoStationsData = pd.read_csv(file_path, index_col='_time', parse_dates=True)\n",
    "meteoStationsData[\"code\"] = meteoStationsData[\"nodeId\"].str[-4:].astype(int)\n",
    "meteoStationsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual filter on the weather meteostations of KMI because the ghi in the database is limited to these few stations\n",
    "codesInDatabase = [6434, 6438, 6455, 6459, 6464, 6472, 6477, 6484]\n",
    "#get only data of stations in the database\n",
    "df_meteo = df_combined[df_combined[\"code\"].isin(codesInDatabase)]\n",
    "df_meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ea9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the ghi data of the database with the KMI weather data\n",
    "df_meteo.index = pd.to_datetime(df_meteo.index)\n",
    "#reset index to merge on both timestamp and code\n",
    "meteoStationsData_reset = meteoStationsData.reset_index()\n",
    "df_meteo_reset = df_meteo.reset_index()\n",
    "\n",
    "df_meteo_reset.rename(columns={'timestamp': '_time'}, inplace=True)\n",
    "\n",
    "df_meteo_reset['_time'] = pd.to_datetime(df_meteo_reset['_time'])\n",
    "df_meteo_reset['_time'] = df_meteo_reset['_time'].dt.tz_localize('UTC')\n",
    "\n",
    "\n",
    "#merge on both timestamp and code\n",
    "merged_df = pd.merge(meteoStationsData_reset, df_meteo_reset, on=['_time', 'code'], how='inner')\n",
    "\n",
    "#set timestamp back as index\n",
    "merged_df.set_index('_time', inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c148e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add lat lon again and calculate distance\n",
    "df_unique_stations = merged_df.drop_duplicates(subset=\"code\", keep=\"first\")\n",
    "df_unique_stations[['lat', 'lon']] = df_unique_stations['the_geom'].str.extract(r'POINT \\(([^ ]+) ([^ ]+)\\)').astype(float)\n",
    "df_unique_stations['distance_km'] = df_unique_stations.apply(lambda row: haversine(lat, lon, row['lat'], row['lon']), axis=1)\n",
    "df_unique_stations = df_unique_stations.sort_values(\"distance_km\")\n",
    "df_unique_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e8d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e08706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2659b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b9e7281",
   "metadata": {},
   "source": [
    "# if not including the ghi data\n",
    "merged_df = df_combined\n",
    "merged_df.index = pd.to_datetime(merged_df.index).tz_localize('UTC')\n",
    "merged_df.index.name = '_time'  # Rename index to '_time'\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886c184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d489592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 3 closest ones and selection of those stations, drop all useless columns\n",
    "df_closest = df_unique_stations[:3]\n",
    "\n",
    "unique_codes = df_closest[\"code\"].unique()\n",
    "unique_codes_list = unique_codes.tolist()\n",
    "\n",
    "#get all data from nearby stations\n",
    "df_meteo = merged_df[merged_df[\"code\"].isin(unique_codes_list)]\n",
    "\n",
    "df_meteo['wind_speed'] = df_meteo['wind_speed_10m'].combine_first(df_meteo['wind_speed_avg_30m'])\n",
    "\n",
    "df_meteo = df_meteo.drop(columns = [\"FID\", \"the_geom\", \"temp_grass_pt100_avg\", \"temp_soil_avg_5cm\",\n",
    "                                            \"temp_soil_avg_10cm\", \"temp_soil_avg_20cm\", \"temp_soil_avg_50cm\",\n",
    "                                            \"qc_flags\", \"wind_speed_10m\", \"wind_speed_avg_30m\"])\n",
    "df_meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17327946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add lat, lon and distance_km to the filtered dataframe\n",
    "df_selection = df_closest[['code', 'lat', 'lon', 'distance_km']]\n",
    "df_meteo = df_meteo.reset_index()\n",
    "df_meteo = pd.merge(df_meteo, df_selection, on=\"code\", how=\"left\")\n",
    "df_meteo = df_meteo.set_index(\"_time\")\n",
    "df_meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508d8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02287ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average weather taking distance into account\n",
    "\n",
    "#define a function to calculate the weighted average for a given column\n",
    "def weighted_average(group, weight_column='distance_km'):\n",
    "    #calculate the weights as the inverse of distance (closer stations get higher weight)\n",
    "    weights = 1 / group[weight_column]\n",
    "    \n",
    "    #compute the weighted average for each column in the group\n",
    "    return (group.drop(columns=[weight_column]).multiply(weights, axis=0)).sum() / weights.sum()\n",
    "\n",
    "#drop the nodeId, not a number\n",
    "df_meteo = df_meteo.drop(columns = [\"nodeId\"])\n",
    "\n",
    "#group by timestamp and apply the weighted average function to each group\n",
    "df_meteo_avg_weighted = df_meteo.groupby(df_meteo.index).apply(weighted_average)\n",
    "\n",
    "df_meteo_avg_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9873bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resample to same granularity of the solar database (from 10min to 15min)\n",
    "df_weather_resampled = df_meteo_avg_weighted.resample('15min').mean()\n",
    "df_weather_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e5179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display rows with NaN values\n",
    "nan_rows = df_weather_resampled[df_weather_resampled.isna().any(axis=1)]\n",
    "\n",
    "#show the rows containing NaN values\n",
    "print(nan_rows)\n",
    "\n",
    "#these are values for which there is no data in the database\n",
    "df_weather_resampled = df_weather_resampled.dropna()\n",
    "df_weather_resampled.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ca0be",
   "metadata": {},
   "source": [
    "# Add the data from the database, choose the right node id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7efe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7847f5f7\n",
    "# 45b46fef\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\inverter_power_data_7847f5f7_normalised_15min.csv\"\n",
    "\n",
    "df_data = pd.read_csv(file_path, index_col='_time', parse_dates=True)\n",
    "#df_data.index = df_data.index.tz_convert('Europe/Brussels')\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine data with weather\n",
    "#if with ghi then we need join right, else join left\n",
    "df_data = df_data.reset_index()\n",
    "\n",
    "df_data['_time'] = pd.to_datetime(df_data['_time'])\n",
    "df_data['_time'] = df_data['_time'].dt.tz_localize('UTC')\n",
    "df_data.set_index('_time', inplace=True)\n",
    "\n",
    "\n",
    "df_data = pd.merge(df_data, df_weather_resampled, how='right', left_index=True, right_index=True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7fb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra features\n",
    "\n",
    "df_data['hour'] = df_data.index.hour\n",
    "df_data['day_of_week'] = df_data.index.dayofweek\n",
    "df_data['month'] = df_data.index.month\n",
    "\n",
    "df_data['hour_sin'] = np.sin(2 * np.pi * df_data['hour'] / 24)\n",
    "df_data['hour_cos'] = np.cos(2 * np.pi * df_data['hour'] / 24)\n",
    "df_data['day_of_year'] = df_data.index.dayofyear\n",
    "df_data['day_of_year_sin'] = np.sin(2 * np.pi * df_data['day_of_year'] / 365)\n",
    "df_data['day_of_year_cos'] = np.cos(2 * np.pi * df_data['day_of_year'] / 365)\n",
    "\n",
    "df_data['minute'] = df_data.index.minute\n",
    "\n",
    "# Encode the 15-minute intervals within an hour\n",
    "df_data['minute_sin'] = np.sin(2 * np.pi * df_data['minute'] / 60)\n",
    "df_data['minute_cos'] = np.cos(2 * np.pi * df_data['minute'] / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[df_data.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb16506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate indices and only keep first one: for the hour change in Belgium\n",
    "df_data = df_data.loc[~df_data.index.duplicated(keep='first')]\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88f06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136a3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f919794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization of other features\n",
    "#initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "columns_to_normalize = [\n",
    "    'precip_quantity', \n",
    "    'temp_dry_shelter_avg', \n",
    "    'temp_soil_avg',\n",
    "    'wind_direction',\n",
    "    'wind_gusts_speed', \n",
    "    'humidity_rel_shelter_avg', \n",
    "    'pressure', \n",
    "    'sun_duration', \n",
    "    'short_wave_from_sky_avg', \n",
    "    'sun_int_avg', \n",
    "    'wind_speed',\n",
    "'diffuseIrradiance_Wpm2',\n",
    "'directNormalIrradiance_Wpm2',\n",
    "'globalHorizontalIrradiance_Wpm2'\n",
    "]\n",
    "\n",
    "#apply MinMax scaling only to other features\n",
    "df_data[columns_to_normalize] = scaler.fit_transform(df_data[columns_to_normalize])\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af97af7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#extra shift of 24 hours ago\n",
    "df_data[\"normalized_value_shift_24\"] = df_data[['normalized_value']].shift(freq='D')\n",
    "df_data = df_data.dropna()\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba53784",
   "metadata": {},
   "source": [
    "# for test including future weather (as approximation of future forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89cd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.loc[:, \"precip_quantity_future\"] = df_data[['precip_quantity']].shift(freq='-1D')\n",
    "df_data.loc[:, \"temp_soil_avg_future\"] = df_data[['temp_soil_avg']].shift(freq='-1D')\n",
    "df_data.loc[:, \"wind_direction_future\"] = df_data[['wind_direction']].shift(freq='-1D')\n",
    "df_data.loc[:, \"wind_gusts_speed_future\"] = df_data[['wind_gusts_speed']].shift(freq='-1D')\n",
    "df_data.loc[:, \"humidity_rel_shelter_avg_future\"] = df_data[['humidity_rel_shelter_avg']].shift(freq='-1D')\n",
    "df_data.loc[:, \"pressure_future\"] = df_data[['pressure']].shift(freq='-1D')\n",
    "df_data.loc[:, \"sun_duration_future\"] = df_data[['sun_duration']].shift(freq='-1D')\n",
    "df_data.loc[:, \"short_wave_from_sky_avg_future\"] = df_data[['short_wave_from_sky_avg']].shift(freq='-1D')\n",
    "df_data.loc[:, \"sun_int_avg_future\"] = df_data[['sun_int_avg']].shift(freq='-1D')\n",
    "df_data.loc[:, \"wind_speed_future\"] = df_data[['wind_speed']].shift(freq='-1D')\n",
    "df_data = df_data.dropna()\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517bbb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_data.corr()\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(correlation_matrix[['mean_actualPowerTot_W_inverter']].sort_values(by='mean_actualPowerTot_W_inverter', ascending=False), \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            vmin=-1, vmax=1,\n",
    "            cbar_kws={'label': 'Correlation coefficient'})\n",
    "\n",
    "plt.title(\"Correlation of features with 'mean_actualPowerTot_W_inverter'\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e44c26",
   "metadata": {},
   "source": [
    "# train - cv - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583561cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "input_steps = 4*8\n",
    "output_steps = 4*24    #predict one timestep ahead\n",
    "step_size_train = 1\n",
    "step_size_test = 1      #shift for testing\n",
    "step_size_val = 1\n",
    "\n",
    "#select relevant columns for features and target\n",
    "features = [\n",
    "    \"normalized_value\",\n",
    "     \"day_of_week\", \"month\", \n",
    "    \"hour_sin\", \"hour_cos\", \n",
    "    \"day_of_year_sin\", \"day_of_year_cos\",\n",
    "    \"minute_sin\", \"minute_cos\",\n",
    "    \"temp_dry_shelter_avg\",\n",
    "    \"normalized_value_shift_24\",\n",
    "    'diffuseIrradiance_Wpm2',\n",
    "    'directNormalIrradiance_Wpm2',\n",
    "    'globalHorizontalIrradiance_Wpm2',\n",
    "    \n",
    "    'precip_quantity', \n",
    "    'temp_soil_avg',\n",
    "    'wind_direction',\n",
    "    'wind_gusts_speed', \n",
    "    'humidity_rel_shelter_avg', \n",
    "    'pressure', \n",
    "    'sun_duration', \n",
    "    'short_wave_from_sky_avg', \n",
    "    'sun_int_avg', \n",
    "    'wind_speed',\n",
    "    \n",
    "    #'precip_quantity_future', \n",
    "    #'temp_soil_avg_future',\n",
    "    #'wind_direction_future',\n",
    "    #'wind_gusts_speed_future', \n",
    "    #'humidity_rel_shelter_avg_future', \n",
    "    #'pressure_future', \n",
    "    #'sun_duration_future', \n",
    "    #'short_wave_from_sky_avg_future', \n",
    "    #'sun_int_avg_future', \n",
    "    #'wind_speed_future',\n",
    "]\n",
    "\n",
    "target = \"normalized_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea254b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_window(data, input_steps=1440, output_steps=1, feature_columns=None, target_column=None, step_size=1):\n",
    "    \"\"\"\n",
    "    Generate sliding windows for a given range of data.\n",
    "    - input_steps: Number of timesteps in the input window.\n",
    "    - output_steps: Number of timesteps to predict.\n",
    "    - feature_columns: List of feature column names.\n",
    "    - target_column: Name of the target column.\n",
    "    - step_size: Shift between consecutive windows.\n",
    "    \"\"\"\n",
    "    X, y, X_indices, y_indices = [], [], [], []\n",
    "    for i in range(0, len(data) - input_steps - output_steps + 1, step_size):\n",
    "        # input: feature columns over the input window\n",
    "        X_window = data[feature_columns].iloc[i:i+input_steps]\n",
    "        X.append(X_window)\n",
    "        X_indices.append(data.index[i:i+input_steps])  #store corresponding indices\n",
    "        \n",
    "        # target: target column for the output window\n",
    "        y_window = data[target_column].iloc[i+input_steps:i+input_steps+output_steps]\n",
    "        y.append(y_window)\n",
    "        y_indices.append(data.index[i+input_steps:i+input_steps+output_steps])  #store corresponding indices\n",
    "    \n",
    "    print(\"Generated sliding windows - X.size:\", len(X), \"y.size:\", len(y))\n",
    "    return X, y, X_indices, y_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf626e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train test sizes\n",
    "train_size = 20 * 24 * 4  # 20 days in 15 minutes\n",
    "val_size = 5 * 24 * 4    # 5 days in 15 minutes\n",
    "test_size = 5 * 24 * 4    # 5 days in 15 minutes\n",
    "\n",
    "# generate train-test splits dynamically, jump by test_size forward between splits\n",
    "splits = []\n",
    "for i in range(0, len(df_data) - train_size - test_size + 1, train_size + val_size + test_size):#if all splits are used for training, there can't be\n",
    "    #overlap, so jump train_size + test_size\n",
    "    train_data = df_data.iloc[i:i+train_size]\n",
    "    val_data = df_data.iloc[i+train_size:i+train_size+val_size]\n",
    "    test_data = df_data.iloc[i+train_size+val_size:i+train_size+val_size+test_size]\n",
    "    splits.append((train_data, val_data ,test_data))\n",
    "print(\"number of splits: \", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d35f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data split\n",
    "\n",
    "#storage for training, validation, and test data\n",
    "all_train_X, all_train_X_indices, all_train_y, all_train_y_indices = [], [], [], []\n",
    "all_val_X, all_val_X_indices, all_val_y, all_val_y_indices = [], [], [], []\n",
    "all_test_X, all_test_X_indices, all_test_y, all_test_y_indices = [], [], [], []\n",
    "\n",
    "# loop over all folds to collect training data\n",
    "fold = 0\n",
    "for fold, (train_data, val_data, test_data) in enumerate(splits):\n",
    "    print(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "    #generate sliding windows for training\n",
    "    df_train_X, df_train_y, df_train_X_indices, df_train_y_indices = generate_sliding_window(train_data, input_steps, output_steps, features, target, step_size_train)\n",
    "    \n",
    "    #generate sliding windows for validation\n",
    "    df_val_X, df_val_y, df_val_X_indices, df_val_y_indices = generate_sliding_window(val_data, input_steps, output_steps, features, target, step_size_val)\n",
    "    \n",
    "    #generate sliding windows for testing\n",
    "    df_test_X, df_test_y, df_test_X_indices, df_test_y_indices = generate_sliding_window(test_data, input_steps, output_steps, features, target, step_size_test)\n",
    "\n",
    "    #append training data\n",
    "    all_train_X.extend(df[features].values for df in df_train_X)\n",
    "    all_train_X_indices.extend(df.values for df in df_train_X_indices)\n",
    "    all_train_y.extend(df.values for df in df_train_y)\n",
    "    all_train_y_indices.extend(df.values for df in df_train_y_indices)\n",
    "\n",
    "    #append validation data\n",
    "    all_val_X.extend(df[features].values for df in df_val_X)\n",
    "    all_val_X_indices.extend(df.values for df in df_val_X_indices)\n",
    "    all_val_y.extend(df.values for df in df_val_y)\n",
    "    all_val_y_indices.extend(df.values for df in df_val_y_indices)\n",
    "\n",
    "    #append test data\n",
    "    all_test_X.extend(df[features].values for df in df_test_X)\n",
    "    all_test_X_indices.extend(df.values for df in df_test_X_indices)\n",
    "    all_test_y.extend(df.values for df in df_test_y)\n",
    "    all_test_y_indices.extend(df.values for df in df_test_y_indices)\n",
    "\n",
    "#convert lists to numpy arrays\n",
    "all_train_X, all_train_y = np.array(all_train_X), np.array(all_train_y)\n",
    "all_train_X_indices, all_train_y_indices = np.array(all_train_X_indices), np.array(all_train_y_indices)\n",
    "\n",
    "all_val_X, all_val_y = np.array(all_val_X), np.array(all_val_y)\n",
    "all_val_X_indices, all_val_y_indices = np.array(all_val_X_indices), np.array(all_val_y_indices)\n",
    "\n",
    "all_test_X, all_test_y = np.array(all_test_X), np.array(all_test_y)\n",
    "all_test_X_indices, all_test_y_indices = np.array(all_test_X_indices), np.array(all_test_y_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66705461",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_X = all_train_X.astype(np.float32)\n",
    "all_train_y = all_train_y.astype(np.float32)\n",
    "\n",
    "all_val_X = all_val_X.astype(np.float32)\n",
    "all_val_y = all_val_y.astype(np.float32)\n",
    "\n",
    "all_test_X = all_test_X.astype(np.float32)\n",
    "all_test_y = all_test_y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0170d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isnan(all_train_X).sum())  # Count NaNs\n",
    "print(np.isinf(all_train_X).sum())  # Count Infs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65d706",
   "metadata": {},
   "source": [
    "# benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "#function to compute and store evaluation metrics\n",
    "def evaluate_benchmark(name, y_true, y_pred):\n",
    "    \"\"\"Computes MAE, RMSE, MAPE, and R² and stores in a dictionary.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    #avoid zero division in MAPE\n",
    "    valid_mask = y_true != 0  \n",
    "    mape = np.mean(np.abs((y_true[valid_mask] - y_pred[valid_mask]) / y_true[valid_mask])) * 100  \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    #store results in dictionary\n",
    "    benchmark_results[name] = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R²': r2\n",
    "    }\n",
    "\n",
    "    #print results\n",
    "    print(f\"  Benchmark: {name}\")\n",
    "    print(f\"  Test MAPE: {mape:.2f}%\")\n",
    "    print(f\"  Test R²: {r2:.4f}\")\n",
    "    print(f\"  Test MAE: {mae:.4f}\")\n",
    "    print(f\"  Test RMSE: {rmse:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#define the earlystopping callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",           #monitor loss\n",
    "    min_delta=0,                  #minimum change to qualify as an improvement\n",
    "    patience=5,                   #number of epochs to wait for improvement before stopping\n",
    "    verbose=1,                    #print when stopping early\n",
    "    mode=\"min\",                   # 'min' because we want to minimize the loss\n",
    "    restore_best_weights=True,    #restore weights from the best epoch when stopping\n",
    ")\n",
    "\n",
    "# save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'best_model.keras',   #path to save the best model weights\n",
    "    monitor='val_loss',        #monitor loss\n",
    "    save_best_only=True,       #save only the best weights\n",
    "    mode='min',                #'min' because we want to minimize the loss\n",
    "    verbose=1                  #print when saving the best weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca5853",
   "metadata": {},
   "source": [
    "# uncertainty quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a19008",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ddaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(q):\n",
    "    def loss(y_true, y_pred):\n",
    "        e = y_true - y_pred\n",
    "        return tf.reduce_mean(tf.maximum(q * e, (q - 1) * e))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_quantile_oneshot_model(input_steps, feature_count, output_steps=96, quantiles=[0.05, 0.5, 0.95]):\n",
    "    \"\"\"\n",
    "    Builds a Keras model for one-shot forecasting that predicts multiple quantiles for each output step.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(input_steps, feature_count))\n",
    "\n",
    "    x = layers.LSTM(128, activation='tanh', return_sequences=True)(inputs)\n",
    "    x = layers.LSTM(64, activation='tanh', return_sequences=True)(x)\n",
    "    x = layers.LSTM(32, activation='tanh')(x)\n",
    "\n",
    "    #output a separate Dense layer for each quantile, predicting output_steps values\n",
    "    outputs = [layers.Dense(output_steps, name=f'quantile_{q}')(x) for q in quantiles]\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d8ac41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quantiles = [0.05, 0.5, 0.95]\n",
    "\n",
    "#build the model\n",
    "model_quantile = build_quantile_oneshot_model(input_steps, feature_count=len(features), output_steps=output_steps , quantiles=quantiles)\n",
    "\n",
    "#compile the model using a list of losses\n",
    "model_quantile.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=[quantile_loss(q) for q in quantiles]  #list of separate loss functions\n",
    ")\n",
    "\n",
    "#reshape training targets to match multiple outputs\n",
    "all_train_y_list = [all_train_y] * len(quantiles)\n",
    "all_val_y_list = [all_val_y] * len(quantiles)\n",
    "\n",
    "#train the model\n",
    "history = model_quantile.fit(\n",
    "    all_train_X, all_train_y_list,\n",
    "    validation_data=(all_val_X, all_val_y_list),\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458f1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = model_quantile.predict(all_test_X)  #returns [array_q05, array_q50, array_q95]\n",
    "\n",
    "#extract each quantile prediction\n",
    "y_pred_q05 = y_pred_list[0].flatten()  # 5th percentile\n",
    "y_pred_q50 = y_pred_list[1].flatten()  # 50th percentile (median)\n",
    "y_pred_q95 = y_pred_list[2].flatten()  # 95th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141adb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_y_flat = all_test_y.reshape(-1)  #ensure it's a 1D array\n",
    "all_test_y_indices_flat = all_test_y_indices.reshape(-1)  #flatten indices to match\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'q05': y_pred_q05,\n",
    "    'q50': y_pred_q50,\n",
    "    'q95': y_pred_q95,\n",
    "    'actual': all_test_y_flat\n",
    "}, index=pd.Index(all_test_y_indices_flat, name=\"timestamp\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07734a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "#actual\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results.index, \n",
    "    y=df_results['actual'],\n",
    "    mode='lines', \n",
    "    name='Actual', \n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "#median (q50)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results.index, \n",
    "    y=df_results['q50'],\n",
    "    mode='lines', \n",
    "    name='Predicted Median (q50)',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "#lower quantile (q05) - invisible line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results.index, \n",
    "    y=df_results['q05'],\n",
    "    mode='lines', \n",
    "    name='q05',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "#upper quantile (q95) - fill between q05 and q95\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results.index, \n",
    "    y=df_results['q95'],\n",
    "    mode='lines',\n",
    "    name='95% Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  # fill between this trace and the previous (q05)\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Quantile Forecasting with LSTM',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Value',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d45b35d",
   "metadata": {},
   "source": [
    "# denormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c61cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.reset_index(inplace=True)\n",
    "df_results['timestamp'] = pd.to_datetime(df_results['timestamp'])\n",
    "df_results['timestamp'] = df_results['timestamp'].dt.tz_localize ('UTC')\n",
    "df_results.set_index('timestamp', inplace=True)\n",
    "\n",
    "#bring back to normal data\n",
    "#read in the normalization profile factors\n",
    "\n",
    "#merge the two DataFrames on the 'time' index\n",
    "df_merged_all = df_results.merge(df_data[['adjusted_P_max', 'mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "#lose some data from full_adjusted_df near end since the df_data doesn't have full last day\n",
    "\n",
    "#check for missing values (NaN) in adjusted_P_max\n",
    "if df_merged_all['adjusted_P_max'].isna().any():\n",
    "    print(\"Warning: Some values are missing in the normalization profile.\")\n",
    "\n",
    "#denormalize the predictions by multiplying by the 'adjusted_P_max' column\n",
    "df_merged_all['denormalized_q05'] = df_merged_all['q05'] * df_merged_all['adjusted_P_max']\n",
    "df_merged_all['denormalized_q50'] = df_merged_all['q50'] * df_merged_all['adjusted_P_max']\n",
    "df_merged_all['denormalized_q95'] = df_merged_all['q95'] * df_merged_all['adjusted_P_max']\n",
    "\n",
    "\n",
    "df_merged_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_benchmark(\"uncertainty quantile 1\", df_merged_all['mean_actualPowerTot_W_inverter'] ,df_merged_all[\"denormalized_q50\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b63e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Actual\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all['mean_actualPowerTot_W_inverter'],\n",
    "    mode='lines', \n",
    "    name='mean_actualPowerTot_W_inverter', \n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "# Median (q50)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all['denormalized_q50'],\n",
    "    mode='lines', \n",
    "    name='Predicted Median (q50)',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Lower quantile (q05) - invisible line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all['denormalized_q05'],\n",
    "    mode='lines', \n",
    "    name='q05',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# Upper quantile (q95) - fill between q05 and q95\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all['denormalized_q95'],\n",
    "    mode='lines',\n",
    "    name='90% Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  # fill between this trace and the previous (q05)\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Quantile Forecasting with LSTM',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='mean_actualPowerTot_W_inverter (W)',\n",
    "    #xaxis_rangeslider_visible=True,\n",
    "    margin=dict(t=150),  # Increase top margin to fit legend and title\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # horizontal layout\n",
    "        y=1,           # place it above the plot area\n",
    "        x=0.5,\n",
    "        xanchor='center',\n",
    "        yanchor='bottom'\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray',\n",
    "        range=['2021-10-09', '2021-10-12']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute evaluation metrics\n",
    "def evaluate_benchmark2(y_true, y_pred):\n",
    "    \"\"\"Computes MAE, RMSE, MAPE, and R² and stores in a dictionary.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    #avoid zero division in MAPE\n",
    "    valid_mask = y_true != 0  \n",
    "    mape = np.mean(np.abs((y_true[valid_mask] - y_pred[valid_mask]) / y_true[valid_mask])) * 100  \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    results = {\n",
    "        \"MAPE\": round(mape, 2),\n",
    "        \"R²\": round(r2, 4),\n",
    "        \"MAE\": round(mae, 4),\n",
    "        \"RMSE\": round(rmse, 4),\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57b196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set prediction horizon and initialize lists\n",
    "prediction_horizon = 24  # hours\n",
    "\n",
    "steps = 8  #move through test samples in steps\n",
    "\n",
    "print(f\"Total number of test sets at stepsize {steps}: {len(all_test_X) // steps}\")\n",
    "\n",
    "all_predictions = []  #list to store DataFrames of q05, q50, q95 per test sample\n",
    "\n",
    "amount_of_times = 0\n",
    "\n",
    "#loop over each test sample\n",
    "for test_idx in range(0, len(all_test_X), steps):\n",
    "    input_window = all_test_X[test_idx]\n",
    "    input_window_indices = all_test_X_indices[test_idx]\n",
    "\n",
    "    #predict all 96 steps at once for this sample\n",
    "    y_pred_list = model_quantile.predict(input_window[np.newaxis, :, :])\n",
    "    y_pred_q05 = y_pred_list[0].flatten()\n",
    "    y_pred_q50 = y_pred_list[1].flatten()\n",
    "    y_pred_q95 = y_pred_list[2].flatten()\n",
    "\n",
    "    #generate prediction timestamps based on the last index in the input window\n",
    "    last_index = input_window_indices[-1]\n",
    "    prediction_indices = [last_index + pd.Timedelta(minutes=15 * (i + 1)) for i in range(output_steps)]\n",
    "    \n",
    "    #create DataFrame for this test sample\n",
    "    df_result = pd.DataFrame({\n",
    "        \"q05\": y_pred_q05,\n",
    "        \"q50\": y_pred_q50,\n",
    "        \"q95\": y_pred_q95,\n",
    "    }, index=pd.Index(prediction_indices, name=\"timestamp\"))\n",
    "\n",
    "    all_predictions.append(df_result)\n",
    "\n",
    "    amount_of_times += 1\n",
    "\n",
    "    if amount_of_times % 10 == 0 or amount_of_times == 1:\n",
    "        print(f\"Prediction completed for test sample {amount_of_times}.\")\n",
    "\n",
    "    if amount_of_times >= 1000:\n",
    "        break\n",
    "\n",
    "print(\"Prediction completed for all test samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb63fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the predictions in all the 'subdataframes'\n",
    "test = all_predictions.copy()\n",
    "\n",
    "for i, df in enumerate(test):\n",
    "    timezone = df_data.index.tz  # Get timezone from df_data\n",
    "    df.index = df.index.tz_localize(timezone) if df.index.tz is None else df.index.tz_convert(timezone)\n",
    "    \n",
    "    df_merged_all = []\n",
    "    #merge the two DataFrames on the 'time' index\n",
    "    df_merged_all = df.merge(df_data[['adjusted_P_max', 'mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "    #check for missing values (NaN) in adjusted_P_max\n",
    "    if df_merged_all['adjusted_P_max'].isna().any():\n",
    "        print(\"Warning: Some values are missing in the normalization profile.\")\n",
    "\n",
    "    # currently cut of a part that goes infinite\n",
    "    #df_merged_all = df_merged_all[(df_merged_all[\"predicted_mean\"] > 0) & (df_merged_all[\"predicted_mean\"] < 5)]\n",
    "\n",
    "    df_merged_all = df_merged_all.dropna(subset=['adjusted_P_max'])\n",
    "    \n",
    "    #denormalize the 'mean_actualPowerTot_W_inverter' column by multiplying by the 'adjusted_P_max' column\n",
    "    df_merged_all['denormalized_q50'] = df_merged_all['q50'] * df_merged_all['adjusted_P_max']\n",
    "    df_merged_all['denormalized_q05'] = df_merged_all['q05'] * df_merged_all['adjusted_P_max']\n",
    "    df_merged_all['denormalized_q95'] = df_merged_all['q95'] * df_merged_all['adjusted_P_max']\n",
    "\n",
    "    test[i] = df_merged_all\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3bac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#evaluate all the results\n",
    "all_results = []\n",
    "\n",
    "for df in test:\n",
    "    print(df)\n",
    "    result = evaluate_benchmark2(df['mean_actualPowerTot_W_inverter'], df['denormalized_q50'])\n",
    "    \n",
    "    within_interval = ((df['mean_actualPowerTot_W_inverter'] >= df['denormalized_q05']) &\n",
    "                   (df['mean_actualPowerTot_W_inverter'] <= df['denormalized_q95']))\n",
    "    CP = within_interval.mean()\n",
    "\n",
    "    interval_width = df['denormalized_q95'] - df['denormalized_q05']\n",
    "    MIW = interval_width.mean()\n",
    "    relative_interval_width = interval_width / df['mean_actualPowerTot_W_inverter']\n",
    "    rMIW = relative_interval_width.mean()\n",
    "    \n",
    "    result[\"CP\"] = CP\n",
    "    result[\"MIW\"] = MIW\n",
    "    result[\"rMIW\"] = rMIW\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "#compute average metrics across all DataFrames\n",
    "average_results = {\n",
    "    \"Benchmark\": \"Average Across All\",\n",
    "    \"MAPE\": round(np.mean([r[\"MAPE\"] for r in all_results]), 2),\n",
    "    \"R²\": round(np.mean([r[\"R²\"] for r in all_results]), 4),\n",
    "    \"MAE\": round(np.mean([r[\"MAE\"] for r in all_results]), 4),\n",
    "    \"RMSE\": round(np.mean([r[\"RMSE\"] for r in all_results]), 4),\n",
    "    \"CP\": round(np.mean([r[\"CP\"] for r in all_results]), 4),\n",
    "    \"MIW\": round(np.mean([r[\"MIW\"] for r in all_results]), 4),\n",
    "    \"rMIW\": round(np.mean([r[\"rMIW\"] for r in all_results]), 4),\n",
    "}\n",
    "\n",
    "#print all individual results and the average\n",
    "for i, res in enumerate(all_results):\n",
    "    print(f\"Results for DataFrame {i+1}: {res}\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Final Average Results:\", average_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = test[230]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['denormalized_q50'], mode='lines', name='predicted'))\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['mean_actualPowerTot_W_inverter'], mode='lines', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['denormalized_q05'], mode='lines', name='q05',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# Upper quantile (q95) - fill between q05 and q95\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['denormalized_q95'],mode='lines',name='95% Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  # fill between this trace and the previous (q05)\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title='denormalised',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b6eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"mean_actualPowerTot_W_inverter\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d8298b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75aad505",
   "metadata": {},
   "source": [
    "# test the performance based on how far into the future the prediction is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize list of DataFrames for each time step (96 DataFrames for 96 time steps)\n",
    "time_step_dfs = {i: pd.DataFrame(columns=['actual', 'predicted']) for i in range(output_steps)}\n",
    "\n",
    "#loop over each DataFrame in the test dataset and populate the 96 DataFrames\n",
    "for df in test:\n",
    "    #get the 'actual' and 'predicted' values from the DataFrame\n",
    "    actual_values = df['mean_actualPowerTot_W_inverter'].values\n",
    "    predicted_values = df['denormalized_q50'].values\n",
    "\n",
    "    #populate the DataFrames corresponding to each time step\n",
    "    for i in range(output_steps):  #we have 96 time steps (from 0 to 95)\n",
    "        #create a temporary dataFrame to hold the current actual and predicted values\n",
    "        temp_df = pd.DataFrame({'actual': [actual_values[i] if i < len(actual_values) else np.nan],\n",
    "                                'predicted': [predicted_values[i] if i < len(predicted_values) else np.nan]})\n",
    "        \n",
    "        time_step_dfs[i] = pd.concat([time_step_dfs[i], temp_df], ignore_index=True)\n",
    "\n",
    "#evaluate each DataFrame individually using the evaluate_benchmark2 function\n",
    "all_results = []\n",
    "\n",
    "for i in range(output_steps):\n",
    "    #get the actual and predicted values for the current time step DataFrame\n",
    "    step_df = time_step_dfs[i]\n",
    "\n",
    "    #drop any rows with NaN values\n",
    "    step_df = step_df.dropna()\n",
    "\n",
    "    result = evaluate_benchmark2(step_df['actual'], step_df['predicted'])\n",
    "    result[\"Time Step\"] = i\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "#compute the average results across all time steps\n",
    "average_results = {\n",
    "    \"MAPE\": round(np.mean([r[\"MAPE\"] for r in all_results]), 2),\n",
    "    \"R²\": round(np.mean([r[\"R²\"] for r in all_results]), 4),\n",
    "    \"MAE\": round(np.mean([r[\"MAE\"] for r in all_results]), 4),\n",
    "    \"RMSE\": round(np.mean([r[\"RMSE\"] for r in all_results]), 4),\n",
    "}\n",
    "\n",
    "for res in all_results:\n",
    "    print(f\"Results for Time Step {res['Time Step']}: {res}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"Final Average Results:\", average_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99851a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the metrics for plotting\n",
    "time_steps = [r[\"Time Step\"] for r in all_results]\n",
    "mape_values = [r[\"MAPE\"] for r in all_results]\n",
    "mae_values = [r[\"MAE\"] for r in all_results]\n",
    "rmse_values = [r[\"RMSE\"] for r in all_results]\n",
    "r2_values = [r[\"R²\"] for r in all_results]\n",
    "\n",
    "#create subplots\n",
    "fig = go.Figure()\n",
    "\n",
    "#plot MAPE\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=mape_values, mode='lines', name='MAPE', line=dict(color='blue')))\n",
    "\n",
    "#plot MAE\n",
    "fig.add_trace(go.Scatter(x=time_steps, y=mae_values, mode='lines', name='MAE', line=dict(color='green')))\n",
    "\n",
    "#plot RMSE\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=rmse_values, mode='lines', name='RMSE', line=dict(color='red')))\n",
    "\n",
    "#plot R²\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=r2_values, mode='lines', name='R²', line=dict(color='orange')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Evaluation Metrics Across Time Steps for MAE\",\n",
    "    xaxis_title=\"Time Step\",\n",
    "    yaxis_title=\"MAE Value (W)\",\n",
    "    legend_title=\"Metrics\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f958723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd552d4e",
   "metadata": {},
   "source": [
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\other_nodes\\timestep_results_quantile_oneshot_ee9f3d22.csv\"\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b150c56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec435fe7",
   "metadata": {},
   "source": [
    "# MC dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de519145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_mc_dropout_oneshot_model(input_steps, feature_count, output_steps, dropout_rate=0.1):\n",
    "    inputs = Input(shape=(input_steps, feature_count))\n",
    "    \n",
    "    #LSTM layers with dropout, both during training and inference\n",
    "    x = LSTM(128, activation='tanh', return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)(inputs)\n",
    "    x = LSTM(64, activation='tanh', return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)(x)\n",
    "    x = LSTM(32, activation='tanh')(x)\n",
    "    \n",
    "    #apply dropout during inference as well\n",
    "    x = Lambda(lambda x: tf.keras.backend.dropout(x, level=dropout_rate))(x)\n",
    "    \n",
    "    #output layer for predicting `output_steps` timesteps ahead\n",
    "    outputs = Dense(output_steps)(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_mc_dropout_oneshot = build_mc_dropout_oneshot_model(input_steps, len(features), output_steps, dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = model_mc_dropout_oneshot.fit(all_train_X, all_train_y, validation_data=(all_val_X, all_val_y), epochs=20, batch_size=64, verbose=1, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predictions(model, X_input, num_samples=100):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo Dropout sampling on a trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Keras model with dropout layers.\n",
    "        X_input: Input data for prediction.\n",
    "        num_samples: Number of stochastic forward passes.\n",
    "\n",
    "    Returns:\n",
    "        mean_prediction: Mean of sampled predictions.\n",
    "        std_prediction: Standard deviation of sampled predictions (uncertainty estimate).\n",
    "    \"\"\"\n",
    "    f_passes = []\n",
    "    for i in range(num_samples):\n",
    "        #perform a forward pass with dropout enabled\n",
    "        sample = model(X_input, training=True).numpy().flatten()  #flattening to remove unnecessary dimensions\n",
    "        f_passes.append(sample)\n",
    "        \n",
    "        #print progress every 10 iterations\n",
    "        if (i + 1) % 10 == 0 or i == num_samples - 1:\n",
    "            print(f\"MC Dropout sampling: {i + 1}/{num_samples} iterations completed.\")\n",
    "    \n",
    "    f_passes = np.array(f_passes)\n",
    "    mean_prediction = f_passes.mean(axis=0)  #mean across all MC samples\n",
    "    std_prediction = f_passes.std(axis=0)    #standard deviation for uncertainty\n",
    "    \n",
    "    return mean_prediction, std_prediction\n",
    "\n",
    "num_samples = 100\n",
    "mean_pred, std_pred = mc_dropout_predictions(model_mc_dropout_oneshot, all_test_X, num_samples=num_samples)\n",
    "\n",
    "# Compute 95% confidence interval\n",
    "lower_bound = mean_pred - 1.645 * std_pred\n",
    "upper_bound = mean_pred + 1.645 * std_pred\n",
    "\n",
    "print(\"Mean Prediction:\", mean_pred)\n",
    "print(\"Standard Deviation (Uncertainty):\", std_pred)\n",
    "print(\"95% Confidence Interval:\", (lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_y_flat = all_test_y.reshape(-1)  #ensure it's a 1D array\n",
    "all_test_y_indices_flat = all_test_y_indices.reshape(-1)  #flatten indices to match\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    \"actual\": all_test_y_flat,\n",
    "}, index=pd.Index(all_test_y_indices_flat, name=\"timestamp\"))\n",
    "\n",
    "#create a DataFrame for plotting\n",
    "df_results = pd.DataFrame({\n",
    "    \"timestamp\": df_test.index,\n",
    "    \"predicted_mean\": mean_pred,\n",
    "    \"lower_bound\": lower_bound,\n",
    "    \"upper_bound\": upper_bound,\n",
    "    \"actual\": all_test_y.flatten()\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "#add actual values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results[\"timestamp\"], \n",
    "    y=df_results[\"actual\"],\n",
    "    mode='lines', \n",
    "    name='Actual',\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "#add predicted mean trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results[\"timestamp\"], \n",
    "    y=df_results[\"predicted_mean\"],\n",
    "    mode='lines', \n",
    "    name='Predicted Mean',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "#add lower bound trace (invisible line)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results[\"timestamp\"], \n",
    "    y=df_results[\"lower_bound\"],\n",
    "    mode='lines',\n",
    "    name='Lower Bound',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "#add upper bound trace with fill to the previous trace (lower bound)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results[\"timestamp\"],\n",
    "    y=df_results[\"upper_bound\"],\n",
    "    mode='lines',\n",
    "    name='95% Confidence Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  #fills between this trace and the previous (lower bound) trace\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Solar Power Forecasting with MC Dropout Uncertainty',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Power Output (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d25864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.set_index(\"timestamp\", inplace=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6245d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.reset_index()\n",
    "df_results['timestamp'] = pd.to_datetime(df_results['timestamp'])\n",
    "df_results['timestamp'] = df_results['timestamp'].dt.tz_localize('UTC')\n",
    "df_results.set_index('timestamp', inplace=True)\n",
    "\n",
    "\n",
    "#bring back to normal data\n",
    "#read in the normalization profile factors\n",
    "\n",
    "#merge the two DataFrames on the 'time' index\n",
    "df_merged_all = df_results.merge(df_data[['adjusted_P_max', 'mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "#df_merged_all = df_results.merge(df_data[['mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "#lose some data from full_adjusted_df near end since the df_data doesn't have full last day\n",
    "\n",
    "#check for missing values (NaN) in adjusted_P_max\n",
    "if df_merged_all['adjusted_P_max'].isna().any():\n",
    "    print(\"Warning: Some values are missing in the normalization profile.\")\n",
    "    \n",
    "\n",
    "df_merged_all = df_merged_all[(df_merged_all[\"predicted_mean\"] > 0) & (df_merged_all[\"predicted_mean\"] < 5)]\n",
    "\n",
    "#denormalize the 'mean_actualPowerTot_W_inverter' column by multiplying by the 'adjusted_P_max' column\n",
    "df_merged_all['denormalized_value_predicted'] = df_merged_all['predicted_mean'] * df_merged_all['adjusted_P_max']\n",
    "df_merged_all['denormalized_lower_bound'] = df_merged_all['lower_bound'] * df_merged_all['adjusted_P_max']\n",
    "df_merged_all['denormalized_upper_bound'] = df_merged_all['upper_bound'] * df_merged_all['adjusted_P_max']\n",
    "\n",
    "\n",
    "df_merged_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "#add actual values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all[\"mean_actualPowerTot_W_inverter\"],\n",
    "    mode='lines', \n",
    "    name='Actual',\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "#add predicted mean trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all[\"denormalized_value_predicted\"],\n",
    "    mode='lines', \n",
    "    name='Predicted Mean',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "#add lower bound trace (invisible line)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all[\"denormalized_lower_bound\"],\n",
    "    mode='lines',\n",
    "    name='Lower Bound',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "#add upper bound trace with fill to the previous trace (lower bound)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index,\n",
    "    y=df_merged_all[\"denormalized_upper_bound\"],\n",
    "    mode='lines',\n",
    "    name='95% Confidence Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  #fills between this trace and the previous (lower bound) trace\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "#update layout\n",
    "fig.update_layout(\n",
    "    title='Solar Power Forecasting with MC Dropout Uncertainty',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Power Output (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fda0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_benchmark(\"MC uncertainty 1 step\", df_merged_all['mean_actualPowerTot_W_inverter'] ,df_merged_all[\"denormalized_value_predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88416d4a",
   "metadata": {},
   "source": [
    "# test every testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191310c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set the number of hours to predict ahead\n",
    "prediction_horizon = 24  # number of hours to predict ahead\n",
    "\n",
    "all_predictions = []\n",
    "steps = 8  # step size for iterating over test set\n",
    "\n",
    "print(f\"Total number of test sets at stepsize {steps}: {len(all_test_X) // steps}\")\n",
    "\n",
    "\n",
    "# loop over the entire test set (you can change the amount of test data by adjusting the loop)\n",
    "amount_of_times = 0\n",
    "for test_idx in range(0, len(all_test_X), steps):  # iterate over each test example\n",
    "    starting_window = all_test_X[test_idx]\n",
    "    starting_window_indeces = all_test_X_indices[test_idx]\n",
    "    \n",
    "    input_window = starting_window\n",
    "    input_window_indices = starting_window_indeces\n",
    "\n",
    "    #perform MC Dropout sampling for the one-shot forecast\n",
    "    mean_pred, std_pred = mc_dropout_predictions(model_mc_dropout_oneshot, input_window[np.newaxis, :, :], num_samples=50)\n",
    "\n",
    "    #compute 95% confidence interval\n",
    "    lower_bound = mean_pred - 1.645 * std_pred\n",
    "    upper_bound = mean_pred + 1.645 * std_pred\n",
    "\n",
    "    #generate prediction timestamps based on the last index in the input window\n",
    "    last_index = input_window_indices[-1]\n",
    "    prediction_indices = [last_index + pd.Timedelta(minutes=15 * (i + 1)) for i in range(output_steps)]\n",
    "\n",
    "    #create dataframe to store results for this test example\n",
    "    df_result = pd.DataFrame({\n",
    "        \"predicted_value\": mean_pred,\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound,\n",
    "    }, index=pd.Index(prediction_indices, name=\"timestamp\"))\n",
    "\n",
    "    all_predictions.append(df_result)\n",
    "    \n",
    "    print(\"amount_of_times: \", amount_of_times)\n",
    "\n",
    "    amount_of_times += 1\n",
    "    if amount_of_times >= 1000:\n",
    "        break\n",
    "\n",
    "print(\"Prediction completed for all test samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3bf505",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_predictions.copy()\n",
    "\n",
    "for i, df in enumerate(test):\n",
    "    df_merged_all = []\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['timestamp'] = df['timestamp'].dt.tz_localize('UTC')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    #merge the two DataFrames on the 'time' index\n",
    "    df_merged_all = df.merge(df_data[['adjusted_P_max', 'mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "    #check for missing values (NaN) in adjusted_P_max\n",
    "    if df_merged_all['adjusted_P_max'].isna().any():\n",
    "        print(\"Warning: Some values are missing in the normalization profile.\")\n",
    "\n",
    "    #df_merged_all = df_merged_all[(df_merged_all[\"predicted_mean\"] > 0) & (df_merged_all[\"predicted_mean\"] < 5)]\n",
    "\n",
    "    #denormalize the 'mean_actualPowerTot_W_inverter' column by multiplying by the 'adjusted_P_max' column\n",
    "    df_merged_all['denormalized_value_predicted'] = df_merged_all['predicted_value'] * df_merged_all['adjusted_P_max']\n",
    "    df_merged_all['denormalized_lower_bound'] = df_merged_all['lower_bound'] * df_merged_all['adjusted_P_max']\n",
    "    df_merged_all['denormalized_upper_bound'] = df_merged_all['upper_bound'] * df_merged_all['adjusted_P_max']\n",
    "\n",
    "    df_merged_all = df_merged_all.dropna(subset=['adjusted_P_max'])\n",
    "    \n",
    "    test[i] = df_merged_all\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7377ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for df in test:\n",
    "    result = evaluate_benchmark2(df['mean_actualPowerTot_W_inverter'], df['denormalized_value_predicted'])\n",
    "    \n",
    "    within_interval = ((df['mean_actualPowerTot_W_inverter'] >= df['denormalized_lower_bound']) &\n",
    "                   (df['mean_actualPowerTot_W_inverter'] <= df['denormalized_upper_bound']))\n",
    "    CP = within_interval.mean()\n",
    "\n",
    "    interval_width = df['denormalized_upper_bound'] - df['denormalized_lower_bound']\n",
    "    MIW = interval_width.mean()\n",
    "    relative_interval_width = interval_width / df['mean_actualPowerTot_W_inverter']\n",
    "    rMIW = relative_interval_width.mean()\n",
    "    \n",
    "    result[\"CP\"] = CP\n",
    "    result[\"MIW\"] = MIW\n",
    "    result[\"rMIW\"] = rMIW\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "#compute average metrics across all DataFrames\n",
    "average_results = {\n",
    "    \"Benchmark\": \"Average Across All\",\n",
    "    \"MAPE\": round(np.mean([r[\"MAPE\"] for r in all_results]), 2),\n",
    "    \"R²\": round(np.mean([r[\"R²\"] for r in all_results]), 4),\n",
    "    \"MAE\": round(np.mean([r[\"MAE\"] for r in all_results]), 4),\n",
    "    \"RMSE\": round(np.mean([r[\"RMSE\"] for r in all_results]), 4),\n",
    "    \"CP\": round(np.mean([r[\"CP\"] for r in all_results]), 4),\n",
    "    \"MIW\": round(np.mean([r[\"MIW\"] for r in all_results]), 4),\n",
    "    \"rMIW\": round(np.mean([r[\"rMIW\"] for r in all_results]), 4),\n",
    "}\n",
    "\n",
    "#print all individual results and the average\n",
    "for i, res in enumerate(all_results):\n",
    "    print(f\"Results for DataFrame {i+1}: {res}\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Final Average Results:\", average_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dab3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = test[311]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['denormalized_value_predicted'], mode='lines', name='predicted'))\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['mean_actualPowerTot_W_inverter'], mode='lines', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['denormalized_lower_bound'], mode='lines', name='q05',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# Upper quantile (q95) - fill between q05 and q95\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['denormalized_upper_bound'],mode='lines',name='95% Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  # fill between this trace and the previous (q05)\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title='denormalised',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa921531",
   "metadata": {},
   "source": [
    "# test the performance based on how far into the future the prediction is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da825e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize list of DataFrames for each time step (96 DataFrames for 96 time steps)\n",
    "time_step_dfs = {i: pd.DataFrame(columns=['actual', 'predicted']) for i in range(output_steps)}\n",
    "\n",
    "#loop over each DataFrame in the test dataset and populate the 96 DataFrames\n",
    "for df in test:\n",
    "    #get the 'actual' and 'predicted' values from the DataFrame\n",
    "    actual_values = df['mean_actualPowerTot_W_inverter'].values\n",
    "    predicted_values = df['denormalized_value_predicted'].values\n",
    "\n",
    "    #populate the DataFrames corresponding to each time step\n",
    "    for i in range(output_steps):  #we have 96 time steps (from 0 to 95)\n",
    "        #create a temporary dataFrame to hold the current actual and predicted values\n",
    "        temp_df = pd.DataFrame({'actual': [actual_values[i] if i < len(actual_values) else np.nan],\n",
    "                                'predicted': [predicted_values[i] if i < len(predicted_values) else np.nan]})\n",
    "        \n",
    "        time_step_dfs[i] = pd.concat([time_step_dfs[i], temp_df], ignore_index=True)\n",
    "\n",
    "#evaluate each DataFrame individually using the evaluate_benchmark2 function\n",
    "all_results = []\n",
    "\n",
    "for i in range(output_steps):\n",
    "    #get the actual and predicted values for the current time step DataFrame\n",
    "    step_df = time_step_dfs[i]\n",
    "\n",
    "    #drop any rows with NaN values\n",
    "    step_df = step_df.dropna()\n",
    "\n",
    "    result = evaluate_benchmark2(step_df['actual'], step_df['predicted'])\n",
    "    result[\"Time Step\"] = i\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "#compute the average results across all time steps\n",
    "average_results = {\n",
    "    \"MAPE\": round(np.mean([r[\"MAPE\"] for r in all_results]), 2),\n",
    "    \"R²\": round(np.mean([r[\"R²\"] for r in all_results]), 4),\n",
    "    \"MAE\": round(np.mean([r[\"MAE\"] for r in all_results]), 4),\n",
    "    \"RMSE\": round(np.mean([r[\"RMSE\"] for r in all_results]), 4),\n",
    "}\n",
    "\n",
    "for res in all_results:\n",
    "    print(f\"Results for Time Step {res['Time Step']}: {res}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"Final Average Results:\", average_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the metrics for plotting\n",
    "time_steps = [r[\"Time Step\"] for r in all_results]\n",
    "mape_values = [r[\"MAPE\"] for r in all_results]\n",
    "mae_values = [r[\"MAE\"] for r in all_results]\n",
    "rmse_values = [r[\"RMSE\"] for r in all_results]\n",
    "r2_values = [r[\"R²\"] for r in all_results]\n",
    "\n",
    "#create subplots\n",
    "fig = go.Figure()\n",
    "\n",
    "#plot MAPE\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=mape_values, mode='lines', name='MAPE', line=dict(color='blue')))\n",
    "\n",
    "#plot MAE\n",
    "fig.add_trace(go.Scatter(x=time_steps, y=mae_values, mode='lines', name='MAE', line=dict(color='green')))\n",
    "\n",
    "#plot RMSE\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=rmse_values, mode='lines', name='RMSE', line=dict(color='red')))\n",
    "\n",
    "#plot R²\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=r2_values, mode='lines', name='R²', line=dict(color='orange')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Evaluation Metrics Across Time Steps for MAE\",\n",
    "    xaxis_title=\"Time Step\",\n",
    "    yaxis_title=\"MAE Value\",\n",
    "    legend_title=\"Metrics\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b87ec2",
   "metadata": {},
   "source": [
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\other_nodes\\timestep_results_MC_oneshot_ee9f3d22.csv\"\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a07b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

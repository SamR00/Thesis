{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979155a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.subplots as sp\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import json\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense, Lambda\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the households file with lats and longs + only the ids that are in the database\n",
    "#json files\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\households_in_database.json\"\n",
    "#read JSON into a dataFrame\n",
    "df_households = pd.read_json(file_path)\n",
    "\n",
    "df_households.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f32452",
   "metadata": {},
   "source": [
    "# Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfaf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\aws_10min.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, index_col='timestamp', parse_dates=True)\n",
    "cutoff_timestamp = \"2022-06-19 04:20:00\"\n",
    "\n",
    "df = df.loc[:cutoff_timestamp]\n",
    "\n",
    "#part 2\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\aws_10min_rest.csv\"\n",
    "\n",
    "df2 = pd.read_csv(file_path, index_col='timestamp', parse_dates=True)\n",
    "cutoff_timestamp = \"2022-06-19 04:30:00\"\n",
    "\n",
    "df2 = df2.loc[cutoff_timestamp:]\n",
    "\n",
    "#combine them\n",
    "df_combined = pd.concat([df, df2])\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#haversine formula to compute the great-circle distance between two points\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # earth radius in km\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c  #distance in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique meteostations\n",
    "df_unique_stations = df_combined.drop_duplicates(subset=\"code\", keep=\"first\")\n",
    "df_unique_stations[['lat', 'lon']] = df_unique_stations['the_geom'].str.extract(r'POINT \\(([^ ]+) ([^ ]+)\\)').astype(float)\n",
    "\n",
    "df_unique_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "household_id = \"7847f5f7\"\n",
    "row = df_households[df_households[\"id\"] == household_id]\n",
    "lat = row[\"latitude\"].values[0]\n",
    "lon = row[\"longitude\"].values[0]\n",
    "\n",
    "df_unique_stations['distance_km'] = df_unique_stations.apply(lambda row: haversine(lat, lon, row['lat'], row['lon']), axis=1)\n",
    "df_unique_stations = df_unique_stations.sort_values(\"distance_km\")\n",
    "df_unique_stations.index.names = ['_time']\n",
    "df_unique_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f16e288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7ce7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pin figure import for legend map\n",
    "import base64\n",
    "\n",
    "image_path = \"C:/Users/samr0/OneDrive - KU Leuven/Documents/!School/master/Thesis/notebooks/graphics-large-blue-pin-png.png\"\n",
    "\n",
    "with open(image_path, 'rb') as f:\n",
    "    img_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "#create an <img> tag with the base64 image\n",
    "img_html = f'<img src=\"data:image/png;base64,{img_base64}\" style=\"height:16px; vertical-align:middle; margin-right:8px;\">'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cead6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "#set the center of the map to the average location or a specific point\n",
    "map_center = [df_unique_stations['lat'].mean(), df_unique_stations['lon'].mean()]\n",
    "map = folium.Map(location=map_center, zoom_start=8)\n",
    "\n",
    "df_top3 = df_unique_stations.head(3)\n",
    "\n",
    "#add markers for each unique station\n",
    "for index, row in df_unique_stations.iterrows():\n",
    "    popup_text = f\"Station Code: {row['code']}<br>Distance: {round(row['distance_km'], 2)} km\"\n",
    "    folium.Marker([row['lat'], row['lon']], popup=popup_text).add_to(map)\n",
    "    \n",
    "folium.CircleMarker(\n",
    "    location=[lat, lon],\n",
    "    radius=6,\n",
    "    color='red',\n",
    "    fill=True,\n",
    "    fill_color='red',\n",
    "    fill_opacity=0.9,\n",
    "    popup=\"Target Location\"\n",
    ").add_to(map)\n",
    "\n",
    "for index, row in df_top3.iterrows():\n",
    "    folium.PolyLine(\n",
    "        locations=[[row['lat'], row['lon']], [lat, lon]],\n",
    "        color='blue',\n",
    "        weight=2,\n",
    "        opacity=0.7,\n",
    "        dash_array='5, 5'  # Creates dashed effect: 5px line, 5px gap\n",
    "    ).add_to(map)\n",
    "\n",
    "legend_html = f\"\"\"\n",
    "<div style=\"\n",
    "    position: fixed; \n",
    "    bottom: 200px; left: 50px; width: 200px; height: 120px; \n",
    "    background-color: white; \n",
    "    border:2px solid grey; \n",
    "    z-index:9999;\n",
    "    font-size:14px;\n",
    "    padding: 10px;\n",
    "    box-shadow: 2px 2px 5px rgba(0,0,0,0.3);\n",
    "\">\n",
    "    <b>Legend</b><br>\n",
    "    <div style=\"margin-top: 5px;\">\n",
    "        <span style=\"\n",
    "            display:inline-block;\n",
    "            width: 12px;\n",
    "            height: 12px;\n",
    "            background-color: red;\n",
    "            border-radius: 50%;\n",
    "            margin-right: 8px;\n",
    "            vertical-align: middle;\n",
    "        \"></span>\n",
    "        Target Location\n",
    "    </div>\n",
    "    <div>\n",
    "        <span style=\"\n",
    "            display:inline-block;\n",
    "            width: 12px;\n",
    "            height: 2px;\n",
    "            background-color: blue;\n",
    "            margin: 7px 8px 0 0;\n",
    "            vertical-align: middle;\n",
    "        \"></span>\n",
    "        Distance Line\n",
    "    </div>\n",
    "    <div>\n",
    "        {img_html}\n",
    "        Station Marker\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "\n",
    "#display the map\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec6bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc17cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the ghi values of the database\n",
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\meteoStationsDatabaseData.csv\"\n",
    "\n",
    "meteoStationsData = pd.read_csv(file_path, index_col='_time', parse_dates=True)\n",
    "meteoStationsData[\"code\"] = meteoStationsData[\"nodeId\"].str[-4:].astype(int)\n",
    "meteoStationsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1216ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "codesInDatabase = [6434, 6438, 6455, 6459, 6464, 6472, 6477, 6484]\n",
    "#get only data of stations in the database\n",
    "df_meteo = df_combined[df_combined[\"code\"].isin(codesInDatabase)]\n",
    "df_meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ebc649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the ghi data with the rest of the weather data\n",
    "\n",
    "df_meteo.index = pd.to_datetime(df_meteo.index)\n",
    "#reset index to merge on both timestamp and code\n",
    "meteoStationsData_reset = meteoStationsData.reset_index()\n",
    "df_meteo_reset = df_meteo.reset_index()\n",
    "\n",
    "df_meteo_reset.rename(columns={'timestamp': '_time'}, inplace=True)\n",
    "\n",
    "df_meteo_reset['_time'] = pd.to_datetime(df_meteo_reset['_time'])\n",
    "df_meteo_reset['_time'] = df_meteo_reset['_time'].dt.tz_localize('UTC')\n",
    "\n",
    "\n",
    "#merge on both timestamp and code\n",
    "merged_df = pd.merge(meteoStationsData_reset, df_meteo_reset, on=['_time', 'code'], how='inner')\n",
    "\n",
    "#set timestamp back as index\n",
    "merged_df.set_index('_time', inplace=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get from the stations in ghi data the unique once and the distance to target node\n",
    "\n",
    "df_unique_stations = merged_df.drop_duplicates(subset=\"code\", keep=\"first\")\n",
    "df_unique_stations[['lat', 'lon']] = df_unique_stations['the_geom'].str.extract(r'POINT \\(([^ ]+) ([^ ]+)\\)').astype(float)\n",
    "df_unique_stations['distance_km'] = df_unique_stations.apply(lambda row: haversine(lat, lon, row['lat'], row['lon']), axis=1)\n",
    "df_unique_stations = df_unique_stations.sort_values(\"distance_km\")\n",
    "df_unique_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b40857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b35207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44acb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c10c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46818d18",
   "metadata": {},
   "source": [
    "# if not including the ghi data\n",
    "merged_df = df_combined\n",
    "merged_df = merged_df.rename_axis('_time')\n",
    "merged_df['_time'] = pd.to_datetime(merged_df.index)\n",
    "merged_df['_time'] = merged_df['_time'].dt.tz_localize('UTC')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f626c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6239af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 3 closest ones and selection\n",
    "df_closest = df_unique_stations[:3]\n",
    "\n",
    "unique_codes = df_closest[\"code\"].unique()\n",
    "unique_codes_list = unique_codes.tolist()\n",
    "\n",
    "#get all data from nearby stations\n",
    "df_meteo = merged_df[merged_df[\"code\"].isin(unique_codes_list)]\n",
    "\n",
    "df_meteo = df_meteo.reset_index()\n",
    "\n",
    "df_meteo['wind_speed'] = df_meteo['wind_speed_10m'].combine_first(df_meteo['wind_speed_avg_30m'])\n",
    "\n",
    "df_meteo = df_meteo.drop(columns = [\"FID\", \"the_geom\", \"temp_grass_pt100_avg\", \"temp_soil_avg_5cm\",\n",
    "                                            \"temp_soil_avg_10cm\", \"temp_soil_avg_20cm\", \"temp_soil_avg_50cm\",\n",
    "                                            \"qc_flags\", \"wind_speed_10m\", \"wind_speed_avg_30m\"])\n",
    "\n",
    "#add lat, lon and distance_km\n",
    "df_selection = df_closest[['code', 'lat', 'lon', 'distance_km']]\n",
    "\n",
    "\n",
    "df_meteo = pd.merge(df_meteo, df_selection, on=\"code\", how=\"left\")\n",
    "\n",
    "df_meteo = df_meteo.set_index(\"_time\")\n",
    "df_meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average weather taking distance into account\n",
    "\n",
    "#define a function to calculate the weighted average for a given column\n",
    "def weighted_average(group, weight_column='distance_km'):\n",
    "    #calculate the weights as the inverse of distance (closer stations get higher weight)\n",
    "    weights = 1 / group[weight_column]\n",
    "    \n",
    "    #compute the weighted average for each column in the group\n",
    "    return (group.drop(columns=[weight_column]).multiply(weights, axis=0)).sum() / weights.sum()\n",
    "\n",
    "#drop the nodeId, not a number\n",
    "df_meteo = df_meteo.drop(columns = [\"nodeId\"])\n",
    "\n",
    "#group by timestamp and apply the weighted average function to each group\n",
    "df_meteo_avg_weighted = df_meteo.groupby(df_meteo.index).apply(weighted_average)\n",
    "\n",
    "df_meteo_avg_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdd9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_resampled = df_meteo_avg_weighted.resample('15min').mean()\n",
    "df_weather_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935aaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display rows with NaN values\n",
    "nan_rows = df_weather_resampled[df_weather_resampled.isna().any(axis=1)]\n",
    "\n",
    "#show the rows containing NaN values\n",
    "print(nan_rows.sum())\n",
    "\n",
    "#these are values for which there is no data in the database\n",
    "df_weather_resampled = df_weather_resampled.dropna()\n",
    "df_weather_resampled.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1919694",
   "metadata": {},
   "source": [
    "# Add the data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7efe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\inverter_power_data_7847f5f7_normalised_15min.csv\"\n",
    "\n",
    "df_data = pd.read_csv(file_path, index_col='_time', parse_dates=True)\n",
    "#df_data.index = df_data.index.tz_convert('Europe/Brussels')\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1071a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine data with weather\n",
    "df_data = df_data.reset_index()\n",
    "\n",
    "df_data['_time'] = pd.to_datetime(df_data['_time'])\n",
    "df_data['_time'] = df_data['_time'].dt.tz_localize('UTC')\n",
    "df_data.set_index('_time', inplace=True)\n",
    "\n",
    "\n",
    "df_data = pd.merge(df_data, df_weather_resampled, how='left', left_index=True, right_index=True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7fb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra features\n",
    "\n",
    "df_data['hour'] = df_data.index.hour\n",
    "df_data['day_of_week'] = df_data.index.dayofweek\n",
    "df_data['month'] = df_data.index.month\n",
    "\n",
    "df_data['hour_sin'] = np.sin(2 * np.pi * df_data['hour'] / 24)\n",
    "df_data['hour_cos'] = np.cos(2 * np.pi * df_data['hour'] / 24)\n",
    "df_data['day_of_year'] = df_data.index.dayofyear\n",
    "df_data['day_of_year_sin'] = np.sin(2 * np.pi * df_data['day_of_year'] / 365)\n",
    "df_data['day_of_year_cos'] = np.cos(2 * np.pi * df_data['day_of_year'] / 365)\n",
    "\n",
    "df_data['minute'] = df_data.index.minute\n",
    "\n",
    "# Encode the 15-minute intervals within an hour\n",
    "df_data['minute_sin'] = np.sin(2 * np.pi * df_data['minute'] / 60)\n",
    "df_data['minute_cos'] = np.cos(2 * np.pi * df_data['minute'] / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate indices and only keep first one: for the hour change in Belgium\n",
    "df_data = df_data.loc[~df_data.index.duplicated(keep='first')]\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29af1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization of other features\n",
    "#initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "columns_to_normalize = [\n",
    "    'precip_quantity', \n",
    "    'temp_dry_shelter_avg', \n",
    "    'temp_soil_avg',\n",
    "    'wind_direction',\n",
    "    'wind_gusts_speed', \n",
    "    'humidity_rel_shelter_avg', \n",
    "    'pressure', \n",
    "    'sun_duration', \n",
    "    'short_wave_from_sky_avg', \n",
    "    'sun_int_avg', \n",
    "    'wind_speed',\n",
    "'diffuseIrradiance_Wpm2',\n",
    "'directNormalIrradiance_Wpm2',\n",
    "'globalHorizontalIrradiance_Wpm2'\n",
    "]\n",
    "\n",
    "#apply MinMax scaling only to other features\n",
    "df_data[columns_to_normalize] = scaler.fit_transform(df_data[columns_to_normalize])\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abe393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra shift of 24 hours ago\n",
    "df_data[\"normalized_value_shift_24\"] = df_data[['normalized_value']].shift(freq='D')\n",
    "df_data = df_data.dropna()\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba97f07",
   "metadata": {},
   "source": [
    "# for test including future weather (as approximation of future forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b10eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.loc[:, \"precip_quantity_future\"] = df_data[['precip_quantity']].shift(freq='-1D')\n",
    "df_data.loc[:, \"temp_soil_avg_future\"] = df_data[['temp_soil_avg']].shift(freq='-1D')\n",
    "df_data.loc[:, \"wind_direction_future\"] = df_data[['wind_direction']].shift(freq='-1D')\n",
    "df_data.loc[:, \"wind_gusts_speed_future\"] = df_data[['wind_gusts_speed']].shift(freq='-1D')\n",
    "df_data.loc[:, \"humidity_rel_shelter_avg_future\"] = df_data[['humidity_rel_shelter_avg']].shift(freq='-1D')\n",
    "df_data.loc[:, \"pressure_future\"] = df_data[['pressure']].shift(freq='-1D')\n",
    "df_data.loc[:, \"sun_duration_future\"] = df_data[['sun_duration']].shift(freq='-1D')\n",
    "df_data.loc[:, \"short_wave_from_sky_avg_future\"] = df_data[['short_wave_from_sky_avg']].shift(freq='-1D')\n",
    "df_data.loc[:, \"sun_int_avg_future\"] = df_data[['sun_int_avg']].shift(freq='-1D')\n",
    "df_data.loc[:, \"wind_speed_future\"] = df_data[['wind_speed']].shift(freq='-1D')\n",
    "df_data = df_data.dropna()\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e44c26",
   "metadata": {},
   "source": [
    "# train - cv - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583561cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "input_steps = 4*8\n",
    "output_steps = 1    #predict one timestep ahead\n",
    "step_size_train = 1\n",
    "step_size_test = 1      #shift for testing\n",
    "step_size_val = 1\n",
    "\n",
    "#select relevant columns for features and target\n",
    "features = [\n",
    "    \"normalized_value\",\n",
    "     \"day_of_week\", \"month\", \n",
    "    \"hour_sin\", \"hour_cos\", \n",
    "    \"day_of_year_sin\", \"day_of_year_cos\",\n",
    "    \"minute_sin\", \"minute_cos\",\n",
    "    \"temp_dry_shelter_avg\",\n",
    "    \"normalized_value_shift_24\",\n",
    "    'diffuseIrradiance_Wpm2',\n",
    "    'directNormalIrradiance_Wpm2',\n",
    "    'globalHorizontalIrradiance_Wpm2',\n",
    "    \n",
    "    #'precip_quantity', \n",
    "    #'temp_soil_avg',\n",
    "    #'wind_direction',\n",
    "    #'wind_gusts_speed', \n",
    "    #'humidity_rel_shelter_avg', \n",
    "    #'pressure', \n",
    "    #'sun_duration', \n",
    "    #'short_wave_from_sky_avg', \n",
    "    #'sun_int_avg', \n",
    "    #'wind_speed',\n",
    "    \n",
    "    #'precip_quantity_future', \n",
    "    #'temp_soil_avg_future',\n",
    "    #'wind_direction_future',\n",
    "    #'wind_gusts_speed_future', \n",
    "    #'humidity_rel_shelter_avg_future', \n",
    "    #'pressure_future', \n",
    "    #'sun_duration_future', \n",
    "    #'short_wave_from_sky_avg_future', \n",
    "    #'sun_int_avg_future', \n",
    "    #'wind_speed_future',\n",
    "]\n",
    "\n",
    "target = \"normalized_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea254b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_window(data, input_steps=1440, output_steps=1, feature_columns=None, target_column=None, step_size=1):\n",
    "    \"\"\"\n",
    "    Generate sliding windows for a given range of data.\n",
    "    - input_steps: Number of timesteps in the input window.\n",
    "    - output_steps: Number of timesteps to predict.\n",
    "    - feature_columns: List of feature column names.\n",
    "    - target_column: Name of the target column.\n",
    "    - step_size: Shift between consecutive windows.\n",
    "    \"\"\"\n",
    "    X, y, X_indices, y_indices = [], [], [], []\n",
    "    for i in range(0, len(data) - input_steps - output_steps + 1, step_size):\n",
    "        # input: feature columns over the input window\n",
    "        X_window = data[feature_columns].iloc[i:i+input_steps]\n",
    "        X.append(X_window)\n",
    "        X_indices.append(data.index[i:i+input_steps])  #store corresponding indices\n",
    "        \n",
    "        # target: target column for the output window\n",
    "        y_window = data[target_column].iloc[i+input_steps:i+input_steps+output_steps]\n",
    "        y.append(y_window)\n",
    "        y_indices.append(data.index[i+input_steps:i+input_steps+output_steps])  #store corresponding indices\n",
    "    \n",
    "    print(\"Generated sliding windows - X.size:\", len(X), \"y.size:\", len(y))\n",
    "    return X, y, X_indices, y_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf626e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train test sizes\n",
    "train_size = 20 * 24 * 4  # 20 days in 15 minutes\n",
    "val_size = 5 * 24 * 4    # 5 days in 15 minutes\n",
    "test_size = 5 * 24 * 4    # 5 days in 15 minutes\n",
    "\n",
    "# generate train-test splits dynamically, jump by test_size forward between splits\n",
    "splits = []\n",
    "for i in range(0, len(df_data) - train_size - test_size + 1, train_size + val_size + test_size):#if all splits are used for training, there can't be\n",
    "    #overlap, so jump train_size + test_size\n",
    "    train_data = df_data.iloc[i:i+train_size]\n",
    "    val_data = df_data.iloc[i+train_size:i+train_size+val_size]\n",
    "    test_data = df_data.iloc[i+train_size+val_size:i+train_size+val_size+test_size]\n",
    "    splits.append((train_data, val_data ,test_data))\n",
    "print(\"number of splits: \", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d35f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data split\n",
    "\n",
    "#storage for training, validation, and test data\n",
    "all_train_X, all_train_X_indices, all_train_y, all_train_y_indices = [], [], [], []\n",
    "all_val_X, all_val_X_indices, all_val_y, all_val_y_indices = [], [], [], []\n",
    "all_test_X, all_test_X_indices, all_test_y, all_test_y_indices = [], [], [], []\n",
    "\n",
    "# loop over all folds to collect training data\n",
    "fold = 0\n",
    "for fold, (train_data, val_data, test_data) in enumerate(splits):\n",
    "    print(f\"Processing Fold {fold + 1}\")\n",
    "\n",
    "    #generate sliding windows for training\n",
    "    df_train_X, df_train_y, df_train_X_indices, df_train_y_indices = generate_sliding_window(train_data, input_steps, output_steps, features, target, step_size_train)\n",
    "    \n",
    "    #generate sliding windows for validation\n",
    "    df_val_X, df_val_y, df_val_X_indices, df_val_y_indices = generate_sliding_window(val_data, input_steps, output_steps, features, target, step_size_val)\n",
    "    \n",
    "    #generate sliding windows for testing\n",
    "    df_test_X, df_test_y, df_test_X_indices, df_test_y_indices = generate_sliding_window(test_data, input_steps, output_steps, features, target, step_size_test)\n",
    "\n",
    "    #append training data\n",
    "    all_train_X.extend(df[features].values for df in df_train_X)\n",
    "    all_train_X_indices.extend(df.values for df in df_train_X_indices)\n",
    "    all_train_y.extend(df.values for df in df_train_y)\n",
    "    all_train_y_indices.extend(df.values for df in df_train_y_indices)\n",
    "\n",
    "    #append validation data\n",
    "    all_val_X.extend(df[features].values for df in df_val_X)\n",
    "    all_val_X_indices.extend(df.values for df in df_val_X_indices)\n",
    "    all_val_y.extend(df.values for df in df_val_y)\n",
    "    all_val_y_indices.extend(df.values for df in df_val_y_indices)\n",
    "\n",
    "    #append test data\n",
    "    all_test_X.extend(df[features].values for df in df_test_X)\n",
    "    all_test_X_indices.extend(df.values for df in df_test_X_indices)\n",
    "    all_test_y.extend(df.values for df in df_test_y)\n",
    "    all_test_y_indices.extend(df.values for df in df_test_y_indices)\n",
    "\n",
    "#convert lists to numpy arrays\n",
    "all_train_X, all_train_y = np.array(all_train_X), np.array(all_train_y)\n",
    "all_train_X_indices, all_train_y_indices = np.array(all_train_X_indices), np.array(all_train_y_indices)\n",
    "\n",
    "all_val_X, all_val_y = np.array(all_val_X), np.array(all_val_y)\n",
    "all_val_X_indices, all_val_y_indices = np.array(all_val_X_indices), np.array(all_val_y_indices)\n",
    "\n",
    "all_test_X, all_test_y = np.array(all_test_X), np.array(all_test_y)\n",
    "all_test_X_indices, all_test_y_indices = np.array(all_test_X_indices), np.array(all_test_y_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66705461",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_X = all_train_X.astype(np.float32)\n",
    "all_train_y = all_train_y.astype(np.float32)\n",
    "\n",
    "all_val_X = all_val_X.astype(np.float32)\n",
    "all_val_y = all_val_y.astype(np.float32)\n",
    "\n",
    "all_test_X = all_test_X.astype(np.float32)\n",
    "all_test_y = all_test_y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0170d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isnan(all_train_X).sum())  # Count NaNs\n",
    "print(np.isinf(all_train_X).sum())  # Count Infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a dictionary to store benchmark results\n",
    "benchmark_results = {}\n",
    "\n",
    "#function to compute and store evaluation metrics\n",
    "def evaluate_benchmark(name, y_true, y_pred):\n",
    "    \"\"\"Computes MAE, RMSE, MAPE, and R² and stores in a dictionary.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    #avoid zero division in MAPE\n",
    "    valid_mask = y_true != 0  \n",
    "    mape = np.mean(np.abs((y_true[valid_mask] - y_pred[valid_mask]) / y_true[valid_mask])) * 100  \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    #store results in dictionary\n",
    "    benchmark_results[name] = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R²': r2\n",
    "    }\n",
    "\n",
    "    #print results\n",
    "    print(f\"  Benchmark: {name}\")\n",
    "    print(f\"  Test MAPE: {mape:.2f}%\")\n",
    "    print(f\"  Test R²: {r2:.4f}\")\n",
    "    print(f\"  Test MAE: {mae:.4f}\")\n",
    "    print(f\"  Test RMSE: {rmse:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939f48b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#define the earlystopping callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",           #monitor loss\n",
    "    min_delta=0,                  #minimum change to qualify as an improvement\n",
    "    patience=5,                   #number of epochs to wait for improvement before stopping\n",
    "    verbose=1,                    #print when stopping early\n",
    "    mode=\"min\",                   # 'min' because we want to minimize the loss\n",
    "    restore_best_weights=True,    #restore weights from the best epoch when stopping\n",
    ")\n",
    "\n",
    "# save the best model\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'best_model.keras',   #path to save the best model weights\n",
    "    monitor='val_loss',        #monitor loss\n",
    "    save_best_only=True,       #save only the best weights\n",
    "    mode='min',                #'min' because we want to minimize the loss\n",
    "    verbose=1                  #print when saving the best weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992eb64",
   "metadata": {},
   "source": [
    "# uncertainty part 1: dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mc_dropout_model(input_steps, feature_count, dropout_rate=0.1):\n",
    "    inputs = Input(shape=(input_steps, feature_count))\n",
    "    \n",
    "    # LSTM layers with dropout, return_sequence for next layer, dropout during training, and in the recurrent part as well\n",
    "    x = LSTM(128, activation='tanh', return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)(inputs)\n",
    "    x = LSTM(64, activation='tanh', return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)(inputs)\n",
    "    x = LSTM(32, activation='tanh')(x)\n",
    "    \n",
    "    # ensure dropout is always applied, during training and predicting\n",
    "    x = Lambda(lambda x: tf.keras.backend.dropout(x, level=dropout_rate))(x)\n",
    "    \n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#build model\n",
    "model_uncertain1 = build_mc_dropout_model(input_steps, len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4df42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = model_uncertain1.fit(all_train_X, all_train_y, validation_data=(all_val_X, all_val_y), epochs=20, batch_size=64, verbose=1, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341066bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to perform MC Dropout inference\n",
    "def mc_dropout_predictions(model, X_input, num_samples=100):\n",
    "    \"\"\"\n",
    "    Perform Monte Carlo Dropout sampling on a trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Keras model with dropout layers.\n",
    "        X_input: Input data for prediction.\n",
    "        num_samples: Number of stochastic forward passes.\n",
    "\n",
    "    Returns:\n",
    "        mean_prediction: Mean of sampled predictions.\n",
    "        std_prediction: Standard deviation of sampled predictions (uncertainty estimate).\n",
    "    \"\"\"\n",
    "    f_passes = []\n",
    "    for i in range(num_samples):\n",
    "        #perform a forward pass with dropout enabled\n",
    "        sample = model(X_input, training=True).numpy().flatten()\n",
    "        f_passes.append(sample)\n",
    "        \n",
    "        #Print progress every 10 iterations\n",
    "        #if (i + 1) % 10 == 0 or i == num_samples - 1:\n",
    "        #    print(f\"MC Dropout sampling: {i + 1}/{num_samples} iterations completed.\")\n",
    "    \n",
    "    f_passes = np.array(f_passes)\n",
    "    mean_prediction = f_passes.mean(axis=0)\n",
    "    std_prediction = f_passes.std(axis=0)\n",
    "    \n",
    "    return mean_prediction, std_prediction\n",
    "\n",
    "#run MC Dropout sampling\n",
    "num_samples = 100\n",
    "mean_pred, std_pred = mc_dropout_predictions(model_uncertain1, all_test_X, num_samples=num_samples)\n",
    "\n",
    "#compute 95% confidence interval\n",
    "lower_bound = mean_pred - 1.645 * std_pred\n",
    "upper_bound = mean_pred + 1.645 * std_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_y_flat = all_test_y.reshape(-1)  #ensure it's a 1D array\n",
    "all_test_y_indices_flat = all_test_y_indices.reshape(-1)  #flatten indices to match\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    \"actual\": all_test_y_flat,\n",
    "}, index=pd.Index(all_test_y_indices_flat, name=\"timestamp\"))\n",
    "\n",
    "#create a DataFrame for plotting\n",
    "df_results = pd.DataFrame({\n",
    "    \"timestamp\": df_test.index,\n",
    "    \"predicted_mean\": mean_pred,\n",
    "    \"lower_bound\": lower_bound,\n",
    "    \"upper_bound\": upper_bound,\n",
    "    \"actual\": all_test_y.flatten()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066fd81",
   "metadata": {},
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "#add actual values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results[\"timestamp\"], \n",
    "    y=df_results[\"actual\"],\n",
    "    mode='lines', \n",
    "    name='Actual',\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "#add predicted mean trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results[\"timestamp\"], \n",
    "    y=df_results[\"predicted_mean\"],\n",
    "    mode='lines', \n",
    "    name='Predicted Mean',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "#add lower bound trace (invisible line)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results[\"timestamp\"], \n",
    "    y=df_results[\"lower_bound\"],\n",
    "    mode='lines',\n",
    "    name='Lower Bound',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "#add upper bound trace with fill to the previous trace (lower bound)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results[\"timestamp\"],\n",
    "    y=df_results[\"upper_bound\"],\n",
    "    mode='lines',\n",
    "    name='95% Confidence Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  #fills between this trace and the previous (lower bound) trace\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Solar Power Forecasting with MC Dropout Uncertainty',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Power Output (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb48d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.set_index(\"timestamp\", inplace=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678be9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77a64058",
   "metadata": {},
   "source": [
    "# denormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.reset_index()\n",
    "df_results['timestamp'] = pd.to_datetime(df_results['timestamp'])\n",
    "df_results['timestamp'] = df_results['timestamp'].dt.tz_localize('UTC')\n",
    "df_results.set_index('timestamp', inplace=True)\n",
    "\n",
    "\n",
    "#bring back to normal data\n",
    "#read in the normalization profile factors\n",
    "\n",
    "#merge the two DataFrames on the 'time' index\n",
    "df_merged_all = df_results.merge(df_data[['adjusted_P_max', 'mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "#df_merged_all = df_results.merge(df_data[['mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "#lose some data from full_adjusted_df near end since the df_data doesn't have full last day\n",
    "\n",
    "#check for missing values (NaN) in adjusted_P_max\n",
    "if df_merged_all['adjusted_P_max'].isna().any():\n",
    "    print(\"Warning: Some values are missing in the normalization profile.\")\n",
    "    \n",
    "df_merged_all = df_merged_all[(df_merged_all[\"predicted_mean\"] > 0) & (df_merged_all[\"predicted_mean\"] < 5)]\n",
    "\n",
    "#denormalize the 'mean_actualPowerTot_W_inverter' column by multiplying by the 'adjusted_P_max' column\n",
    "df_merged_all['denormalized_value_predicted'] = df_merged_all['predicted_mean'] * df_merged_all['adjusted_P_max']\n",
    "df_merged_all['denormalized_lower_bound'] = df_merged_all['lower_bound'] * df_merged_all['adjusted_P_max']\n",
    "df_merged_all['denormalized_upper_bound'] = df_merged_all['upper_bound'] * df_merged_all['adjusted_P_max']\n",
    "\n",
    "\n",
    "df_merged_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd114f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "#add actual values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all[\"mean_actualPowerTot_W_inverter\"],\n",
    "    mode='lines', \n",
    "    name='Actual',\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "#add predicted mean trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all[\"denormalized_value_predicted\"],\n",
    "    mode='lines', \n",
    "    name='Predicted Mean',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "#add lower bound trace (invisible line)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index, \n",
    "    y=df_merged_all[\"denormalized_lower_bound\"],\n",
    "    mode='lines',\n",
    "    name='Lower Bound',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "#add upper bound trace with fill to the previous trace (lower bound)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_merged_all.index,\n",
    "    y=df_merged_all[\"denormalized_upper_bound\"],\n",
    "    mode='lines',\n",
    "    name='95% Confidence Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  #fills between this trace and the previous (lower bound) trace\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "#update layout\n",
    "fig.update_layout(\n",
    "    title='Solar Power Forecasting with MC Dropout Uncertainty',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Power Output (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_benchmark(\"uncertainty 1 min\", df_merged_all['mean_actualPowerTot_W_inverter'] ,df_merged_all[\"denormalized_value_predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367dff47",
   "metadata": {},
   "source": [
    "# uncertainty 1 with the testing at every timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62670f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute evaluation metrics\n",
    "def evaluate_benchmark2(y_true, y_pred):\n",
    "    \"\"\"Computes MAE, RMSE, MAPE, and R² and stores in a dictionary.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    #avoid zero division in MAPE\n",
    "    valid_mask = y_true != 0  \n",
    "    mape = np.mean(np.abs((y_true[valid_mask] - y_pred[valid_mask]) / y_true[valid_mask])) * 100  \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    results = {\n",
    "        \"MAPE\": round(mape, 2),\n",
    "        \"R²\": round(r2, 4),\n",
    "        \"MAE\": round(mae, 4),\n",
    "        \"RMSE\": round(rmse, 4),\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61ad93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853bdfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the number of hours to predict ahead\n",
    "prediction_horizon = 24  #number of hours to predict ahead\n",
    "\n",
    "all_predictions = []\n",
    "all_predictions_recursive = []\n",
    "all_predictions_indices = []\n",
    "\n",
    "\n",
    "all_predictions_lower = []\n",
    "all_predictions_upper = []\n",
    "\n",
    "steps = 24\n",
    "\n",
    "print(f\"Total number of test sets at stepsize {steps}: {len(all_test_X)// steps}\")\n",
    "\n",
    "#loop over the entire test set\n",
    "amount_of_times = 0\n",
    "for test_idx in range(0, len(all_test_X), steps):  #iterate over each test example\n",
    "    starting_window = all_test_X[test_idx]\n",
    "    starting_window_indeces = all_test_X_indices[test_idx]\n",
    "    #print(starting_window_indeces)\n",
    "\n",
    "    input_window = starting_window\n",
    "    input_window_indices = starting_window_indeces\n",
    "\n",
    "    predictions_recursive = []\n",
    "    predictions_indices = []\n",
    "    predictions_lower = []\n",
    "    predictions_upper = []\n",
    "\n",
    "    for i in range(prediction_horizon * 4):  #total steps in 15minutes intervals\n",
    "        #predict next minute\n",
    "        num_samples = 10\n",
    "        mean_pred, std_pred = mc_dropout_predictions(model_uncertain1, input_window[np.newaxis, :, :], num_samples=num_samples)\n",
    "        #print(mean_pred)\n",
    "        #compute 95% confidence interval\n",
    "        lower_bound = mean_pred - 1.645 * std_pred\n",
    "        upper_bound = mean_pred + 1.645 * std_pred\n",
    "        \n",
    "        prediction = mean_pred\n",
    "        predictions_recursive.append(prediction[0])\n",
    "        predictions_lower.append(lower_bound[0])\n",
    "        predictions_upper.append(upper_bound[0])\n",
    "\n",
    "\n",
    "        #update time indices for predictions\n",
    "        next_index = input_window_indices[-1] + pd.Timedelta(minutes=15)\n",
    "        predictions_indices.append(next_index)\n",
    "\n",
    "        #update the input window for the next step (shift window to the left)\n",
    "        input_window = np.roll(input_window, -1, axis=0)\n",
    "        \n",
    "        #update the last element of the window with the prediction\n",
    "        input_window[-1, 0] = prediction[0]\n",
    "        \n",
    "        #update dayofweek\n",
    "        input_window[-1, 1] = next_index.dayofweek\n",
    "        input_window[-1, 2] = next_index.month\n",
    "\n",
    "        #update hour sin and cos\n",
    "        next_hour = next_index.hour\n",
    "        input_window[-1, 3] = np.sin(2 * np.pi * next_hour / 24)\n",
    "        input_window[-1, 4] = np.cos(2 * np.pi * next_hour / 24)\n",
    "        \n",
    "        next_minute = next_index.minute\n",
    "\n",
    "        # Encode the 15-minute intervals within an hour\n",
    "        input_window[-1, 5] = np.sin(2 * np.pi * next_minute / 60)\n",
    "        input_window[-1, 6] = np.cos(2 * np.pi * next_minute / 60)\n",
    "        \n",
    "        next_minute = next_index.minute\n",
    "        input_window[-1, 7] = np.sin(2 * np.pi * next_minute / 60)\n",
    "        input_window[-1, 8] = np.cos(2 * np.pi * next_minute / 60)\n",
    "        \n",
    "        \n",
    "        ##################################################\n",
    "        #test future data as direct insert in weather\n",
    "        \n",
    "        \n",
    "        #add the other features from the previous day\n",
    "        #next_index_previous_day = next_index - pd.Timedelta(days=1)\n",
    "        \n",
    "        #for daylight savings, timestamps not present\n",
    "        # Check if the exact timestamp exists in the index\n",
    "        #if next_index_previous_day in df_data.index:\n",
    "        #    data_next_day = df_data.loc[next_index_previous_day]\n",
    "        #else:\n",
    "        #    #make next_index_previous_day also timezone aware\n",
    "        #    next_index_previous_day = next_index_previous_day.tz_localize(df_data.index.tzinfo)\n",
    "        #    # If not, get the next closest available timestamp (forward direction)\n",
    "        #    closest_timestamp_idx = df_data.index.searchsorted(next_index_previous_day, side='right')\n",
    "        #    closest_timestamp = df_data.index[closest_timestamp_idx] if closest_timestamp_idx < len(df_data) else df_data.index[-1]\n",
    "\n",
    "        #    data_next_day = df_data.loc[closest_timestamp]\n",
    "        \n",
    "        if next_index in df_data.index:\n",
    "            data_next_day = df_data.loc[next_index]\n",
    "        else:\n",
    "            next_index = next_index.tz_localize(df_data.index.tzinfo)\n",
    "            closest_timestamp_idx = df_data.index.searchsorted(next_index, side='right')\n",
    "            closest_timestamp = df_data.index[closest_timestamp_idx] if closest_timestamp_idx < len(df_data) else df_data.index[-1]\n",
    "\n",
    "            data_next_day = df_data.loc[closest_timestamp]\n",
    "            \n",
    "        \n",
    "        #######################################################\n",
    "        \n",
    "        if isinstance(data_next_day, pd.Series):\n",
    "            data_next_day = data_next_day.to_frame().T\n",
    "            \n",
    "        try:\n",
    "            input_window[-1, 9] = data_next_day.iloc[0][\"temp_dry_shelter_avg\"]\n",
    "            input_window[-1, 10] = data_next_day.iloc[0][\"normalized_value_shift_24\"]\n",
    "            input_window[-1, 11] = data_next_day.iloc[0][\"diffuseIrradiance_Wpm2\"]\n",
    "            input_window[-1, 12] = data_next_day.iloc[0][\"directNormalIrradiance_Wpm2\"]\n",
    "            input_window[-1, 13] = data_next_day.iloc[0][\"globalHorizontalIrradiance_Wpm2\"]\n",
    "            \n",
    "            input_window[-1, 14] = data_next_day.iloc[0][\"precip_quantity\"]\n",
    "            input_window[-1, 15] = data_next_day.iloc[0][\"temp_soil_avg\"]\n",
    "            input_window[-1, 16] = data_next_day.iloc[0][\"wind_direction\"]\n",
    "            input_window[-1, 17] = data_next_day.iloc[0][\"wind_gusts_speed\"]\n",
    "            input_window[-1, 18] = data_next_day.iloc[0][\"humidity_rel_shelter_avg\"]\n",
    "            input_window[-1, 19] = data_next_day.iloc[0][\"pressure\"]\n",
    "            input_window[-1, 20] = data_next_day.iloc[0][\"sun_duration\"]\n",
    "            input_window[-1, 21] = data_next_day.iloc[0][\"short_wave_from_sky_avg\"]\n",
    "            input_window[-1, 22] = data_next_day.iloc[0][\"sun_int_avg\"]\n",
    "            input_window[-1, 23] = data_next_day.iloc[0][\"wind_speed\"]\n",
    "            \n",
    "            #input_window[-1, 24] = data_next_day.iloc[0][\"precip_quantity_future\"]\n",
    "            #input_window[-1, 25] = data_next_day.iloc[0][\"temp_soil_avg_future\"]\n",
    "            #input_window[-1, 26] = data_next_day.iloc[0][\"wind_direction_future\"]\n",
    "            #input_window[-1, 27] = data_next_day.iloc[0][\"wind_gusts_speed_future\"]\n",
    "            #input_window[-1, 28] = data_next_day.iloc[0][\"humidity_rel_shelter_avg_future\"]\n",
    "            #input_window[-1, 29] = data_next_day.iloc[0][\"pressure_future\"]\n",
    "            #input_window[-1, 30] = data_next_day.iloc[0][\"sun_duration_future\"]\n",
    "            #input_window[-1, 31] = data_next_day.iloc[0][\"short_wave_from_sky_avg_future\"]\n",
    "            #input_window[-1, 32] = data_next_day.iloc[0][\"sun_int_avg_future\"]\n",
    "            #input_window[-1, 33] = data_next_day.iloc[0][\"wind_speed_future\"]\n",
    "            \n",
    "            \n",
    "        except KeyError:\n",
    "            input_window[-1, 9] = np.nan\n",
    "            input_window[-1, 10] = np.nan\n",
    "            input_window[-1, 11] = np.nan\n",
    "            input_window[-1, 12] = np.nan\n",
    "            input_window[-1, 13] = np.nan\n",
    "            \n",
    "            input_window[-1, 14] = np.nan\n",
    "            input_window[-1, 15] = np.nan\n",
    "            input_window[-1, 16] = np.nan\n",
    "            input_window[-1, 17] = np.nan\n",
    "            input_window[-1, 18] = np.nan\n",
    "            input_window[-1, 19] = np.nan\n",
    "            input_window[-1, 20] = np.nan\n",
    "            input_window[-1, 21] = np.nan\n",
    "            input_window[-1, 22] = np.nan\n",
    "            input_window[-1, 23] = np.nan\n",
    "            \n",
    "            #input_window[-1, 24] = np.nan\n",
    "            #input_window[-1, 25] = np.nan\n",
    "            #input_window[-1, 26] = np.nan\n",
    "            #input_window[-1, 27] = np.nan\n",
    "            #input_window[-1, 28] = np.nan\n",
    "            #input_window[-1, 29] = np.nan\n",
    "            #input_window[-1, 30] = np.nan\n",
    "            #input_window[-1, 31] = np.nan\n",
    "            #input_window[-1, 32] = np.nan\n",
    "            #input_window[-1, 33] = np.nan\n",
    "            \n",
    "        #update indices\n",
    "        input_window_indices = np.roll(input_window_indices, -1, axis=0)\n",
    "        input_window_indices[-1] = next_index\n",
    "            \n",
    "        # print progress for every 100 steps or at the last step\n",
    "        if i % 10 == 0 or i == prediction_horizon * 4 - 1:\n",
    "            print(f\"Prediction progress for test set {test_idx//steps + 1}: Step {i + 1} / {prediction_horizon * 4} ({(i + 1) / (prediction_horizon * 4) * 100:.2f}%)\")\n",
    "\n",
    "        \n",
    "    \n",
    "    #convert predictions and indices to numpy arrays\n",
    "    predictions_recursive = np.array(predictions_recursive)\n",
    "    predictions_indices = np.array(predictions_indices)\n",
    "\n",
    "    #store predictions for this test example\n",
    "    all_predictions_recursive.append(predictions_recursive)\n",
    "    all_predictions_indices.append(predictions_indices)\n",
    "    all_predictions_upper.append(predictions_upper)\n",
    "    all_predictions_lower.append(predictions_lower)\n",
    "\n",
    "    #store predictions for this test example\n",
    "    #add in individual dataframe\n",
    "    df_result = pd.DataFrame({\n",
    "        \"predicted_value\": predictions_recursive,\n",
    "        \"lower_bound\": predictions_lower,\n",
    "        \"upper_bound\": predictions_upper,\n",
    "    }, index=pd.Index(predictions_indices, name=\"timestamp\"))\n",
    "\n",
    "        \n",
    "    all_predictions.append(df_result)\n",
    "    \n",
    "    print(\"amount_of_times: \", amount_of_times)\n",
    "    \n",
    "    amount_of_times += 1\n",
    "    \n",
    "    #if(amount_of_times >= 1000):\n",
    "    #    break\n",
    "\n",
    "print(\"Prediction completed for all test samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911878b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23bd447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f09f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624955d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_predictions.copy()\n",
    "\n",
    "for i, df in enumerate(test):\n",
    "    df_merged_all = []\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['timestamp'] = df['timestamp'].dt.tz_localize('UTC')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    #merge the two DataFrames on the 'time' index\n",
    "    df_merged_all = df.merge(df_data[['adjusted_P_max', 'mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "    #check for missing values (NaN) in adjusted_P_max\n",
    "    if df_merged_all['adjusted_P_max'].isna().any():\n",
    "        print(\"Warning: Some values are missing in the normalization profile.\")\n",
    "\n",
    "    #denormalize the 'mean_actualPowerTot_W_inverter' column by multiplying by the 'adjusted_P_max' column\n",
    "    df_merged_all['denormalized_value_predicted'] = df_merged_all['predicted_value'] * df_merged_all['adjusted_P_max']\n",
    "    df_merged_all['denormalized_lower_bound'] = df_merged_all['lower_bound'] * df_merged_all['adjusted_P_max']\n",
    "    df_merged_all['denormalized_upper_bound'] = df_merged_all['upper_bound'] * df_merged_all['adjusted_P_max']\n",
    "\n",
    "    test[i] = df_merged_all\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(test):\n",
    "    before = len(df)\n",
    "    after = len(df.dropna())\n",
    "    print(f\"test[{i}]: {before - after} rows dropped due to NaNs\")\n",
    "    test[i] = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91803c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for df in test:\n",
    "    result = evaluate_benchmark2(df['mean_actualPowerTot_W_inverter'], df['denormalized_value_predicted'])\n",
    "    \n",
    "    within_interval = ((df['mean_actualPowerTot_W_inverter'] >= df['denormalized_lower_bound']) &\n",
    "                   (df['mean_actualPowerTot_W_inverter'] <= df['denormalized_upper_bound']))\n",
    "    CP = within_interval.mean()\n",
    "\n",
    "    interval_width = df['denormalized_upper_bound'] - df['denormalized_lower_bound']\n",
    "    MIW = interval_width.mean()\n",
    "    relative_interval_width = interval_width / df['mean_actualPowerTot_W_inverter']\n",
    "    rMIW = relative_interval_width.mean()\n",
    "    \n",
    "    result[\"CP\"] = CP\n",
    "    result[\"MIW\"] = MIW\n",
    "    result[\"rMIW\"] = rMIW\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "#compute average metrics across all DataFrames\n",
    "average_results = {\n",
    "    \"Benchmark\": \"Average Across All\",\n",
    "    \"MAPE\": round(np.mean([r[\"MAPE\"] for r in all_results]), 2),\n",
    "    \"R²\": round(np.mean([r[\"R²\"] for r in all_results]), 4),\n",
    "    \"MAE\": round(np.mean([r[\"MAE\"] for r in all_results]), 4),\n",
    "    \"RMSE\": round(np.mean([r[\"RMSE\"] for r in all_results]), 4),\n",
    "    \"CP\": round(np.mean([r[\"CP\"] for r in all_results]), 4),\n",
    "    \"MIW\": round(np.mean([r[\"MIW\"] for r in all_results]), 4),\n",
    "    \"rMIW\": round(np.mean([r[\"rMIW\"] for r in all_results]), 4),\n",
    "}\n",
    "\n",
    "#print all individual results and the average\n",
    "for i, res in enumerate(all_results):\n",
    "    print(f\"Results for DataFrame {i+1}: {res}\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Final Average Results:\", average_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = test[100]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "#add actual values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dataframe.index, \n",
    "    y=dataframe[\"mean_actualPowerTot_W_inverter\"],\n",
    "    mode='lines', \n",
    "    name='Actual',\n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "#add predicted mean trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dataframe.index, \n",
    "    y=dataframe[\"denormalized_value_predicted\"],\n",
    "    mode='lines', \n",
    "    name='Predicted Mean',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "#add lower bound trace (invisible line)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dataframe.index, \n",
    "    y=dataframe[\"denormalized_lower_bound\"],\n",
    "    mode='lines',\n",
    "    name='Lower Bound',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "#add upper bound trace with fill to the previous trace (lower bound)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dataframe.index,\n",
    "    y=dataframe[\"denormalized_upper_bound\"],\n",
    "    mode='lines',\n",
    "    name='95% Confidence Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  #fills between this trace and the previous (lower bound) trace\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "#update layout\n",
    "fig.update_layout(\n",
    "    title='Solar Power Forecasting with MC Dropout Uncertainty',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Power Output (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36465031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_steps_day = 96\n",
    "#initialize list of DataFrames for each time step (96 DataFrames for 96 time steps)\n",
    "time_step_dfs = {i: pd.DataFrame(columns=['actual', 'predicted']) for i in range(output_steps_day)}\n",
    "\n",
    "#loop over each DataFrame in the test dataset and populate the 96 DataFrames\n",
    "for df in test:\n",
    "    #get the 'actual' and 'predicted' values from the DataFrame\n",
    "    actual_values = df['mean_actualPowerTot_W_inverter'].values\n",
    "    predicted_values = df['denormalized_value_predicted'].values\n",
    "\n",
    "    #populate the DataFrames corresponding to each time step\n",
    "    for i in range(output_steps_day):  #we have 96 time steps (from 0 to 95)\n",
    "        #create a temporary dataFrame to hold the current actual and predicted values\n",
    "        temp_df = pd.DataFrame({'actual': [actual_values[i] if i < len(actual_values) else np.nan],\n",
    "                                'predicted': [predicted_values[i] if i < len(predicted_values) else np.nan]})\n",
    "        \n",
    "        time_step_dfs[i] = pd.concat([time_step_dfs[i], temp_df], ignore_index=True)\n",
    "\n",
    "#evaluate each DataFrame individually using the evaluate_benchmark2 function\n",
    "all_results = []\n",
    "\n",
    "for i in range(output_steps_day):\n",
    "    #get the actual and predicted values for the current time step DataFrame\n",
    "    step_df = time_step_dfs[i]\n",
    "\n",
    "    #drop any rows with NaN values\n",
    "    step_df = step_df.dropna()\n",
    "\n",
    "    result = evaluate_benchmark2(step_df['actual'], step_df['predicted'])\n",
    "    result[\"Time Step\"] = i\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "#compute the average results across all time steps\n",
    "average_results = {\n",
    "    \"MAPE\": round(np.mean([r[\"MAPE\"] for r in all_results]), 2),\n",
    "    \"R²\": round(np.mean([r[\"R²\"] for r in all_results]), 4),\n",
    "    \"MAE\": round(np.mean([r[\"MAE\"] for r in all_results]), 4),\n",
    "    \"RMSE\": round(np.mean([r[\"RMSE\"] for r in all_results]), 4),\n",
    "}\n",
    "\n",
    "for res in all_results:\n",
    "    print(f\"Results for Time Step {res['Time Step']}: {res}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"Final Average Results:\", average_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the metrics for plotting\n",
    "time_steps = [r[\"Time Step\"] for r in all_results]\n",
    "mape_values = [r[\"MAPE\"] for r in all_results]\n",
    "mae_values = [r[\"MAE\"] for r in all_results]\n",
    "rmse_values = [r[\"RMSE\"] for r in all_results]\n",
    "r2_values = [r[\"R²\"] for r in all_results]\n",
    "\n",
    "#create subplots\n",
    "fig = go.Figure()\n",
    "\n",
    "#plot MAPE\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=mape_values, mode='lines', name='MAPE', line=dict(color='blue')))\n",
    "\n",
    "#plot MAE\n",
    "fig.add_trace(go.Scatter(x=time_steps, y=mae_values, mode='lines', name='MAE', line=dict(color='green')))\n",
    "\n",
    "#plot RMSE\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=rmse_values, mode='lines', name='RMSE', line=dict(color='red')))\n",
    "\n",
    "#plot R²\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=r2_values, mode='lines', name='R²', line=dict(color='orange')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Evaluation Metrics Across Time Steps\",\n",
    "    xaxis_title=\"Time Step\",\n",
    "    yaxis_title=\"Metric Value\",\n",
    "    legend_title=\"Metrics\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c2a3b",
   "metadata": {},
   "source": [
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\timestep_results_MC_recursive_test7_fixed.csv\"\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603e2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5d25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9c6566d",
   "metadata": {},
   "source": [
    "# uncertainty quantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb43d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(q):\n",
    "    def loss(y_true, y_pred):\n",
    "        e = y_true - y_pred\n",
    "        return tf.reduce_mean(tf.maximum(q * e, (q - 1) * e))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb0711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_quantile_model(input_steps, feature_count, quantiles=[0.05, 0.5, 0.95]):\n",
    "    \"\"\"\n",
    "    Builds a Keras model that predicts multiple quantiles at once.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(input_steps, feature_count))\n",
    "    \n",
    "    x = layers.LSTM(128, return_sequences=True)(inputs)\n",
    "    x = layers.LSTM(64, return_sequences=True)(x)\n",
    "    x = layers.LSTM(32)(x)\n",
    "    \n",
    "    #separate Dense layers for each quantile\n",
    "    outputs = [layers.Dense(1, name=f'quantile_{q}')(x) for q in quantiles]\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b78d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quantiles = [0.05, 0.5, 0.95]\n",
    "\n",
    "#build the model\n",
    "model_quantile = build_quantile_model(input_steps, feature_count=len(features), quantiles=quantiles)\n",
    "\n",
    "#compile the model using a list of losses\n",
    "model_quantile.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=[quantile_loss(q) for q in quantiles]  #list of separate loss functions\n",
    ")\n",
    "\n",
    "#reshape training targets to match multiple outputs\n",
    "all_train_y_list = [all_train_y] * len(quantiles)\n",
    "all_val_y_list = [all_val_y] * len(quantiles)\n",
    "\n",
    "#train the model\n",
    "history = model_quantile.fit(\n",
    "    all_train_X, all_train_y_list,  # Pass list of targets\n",
    "    validation_data=(all_val_X, all_val_y_list),\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317cb86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = model_quantile.predict(all_test_X)  #returns [array_q05, array_q50, array_q95]\n",
    "\n",
    "#extract each quantile prediction\n",
    "y_pred_q05 = y_pred_list[0].flatten()  # 5th percentile\n",
    "y_pred_q50 = y_pred_list[1].flatten()  # 50th percentile (median)\n",
    "y_pred_q95 = y_pred_list[2].flatten()  # 95th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbf7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_y_flat = all_test_y.reshape(-1)  #ensure it's a 1D array\n",
    "all_test_y_indices_flat = all_test_y_indices.reshape(-1)  #flatten indices to match\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'q05': y_pred_q05,\n",
    "    'q50': y_pred_q50,\n",
    "    'q95': y_pred_q95,\n",
    "    'actual': all_test_y_flat\n",
    "}, index=pd.Index(all_test_y_indices_flat, name=\"timestamp\"))\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Actual\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results.index, \n",
    "    y=df_results['actual'],\n",
    "    mode='lines', \n",
    "    name='Actual', \n",
    "    line=dict(color='black')\n",
    "))\n",
    "\n",
    "# Median (q50)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results.index, \n",
    "    y=df_results['q50'],\n",
    "    mode='lines', \n",
    "    name='Predicted Median (q50)',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "# Lower quantile (q05) - invisible line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results.index, \n",
    "    y=df_results['q05'],\n",
    "    mode='lines', \n",
    "    name='q05',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# Upper quantile (q95) - fill between q05 and q95\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results.index, \n",
    "    y=df_results['q95'],\n",
    "    mode='lines',\n",
    "    name='95% Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  # fill between this trace and the previous (q05)\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Quantile Forecasting with LSTM',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Value',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f013e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcad1e1",
   "metadata": {},
   "source": [
    "# denormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1373fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.reset_index(inplace=True)\n",
    "df_results['timestamp'] = pd.to_datetime(df_results['timestamp'])\n",
    "df_results['timestamp'] = df_results['timestamp'].dt.tz_localize ('UTC')\n",
    "df_results.set_index('timestamp', inplace=True)\n",
    "\n",
    "#bring back to normal data\n",
    "#read in the normalization profile factors\n",
    "\n",
    "#merge the two DataFrames on the 'time' index\n",
    "df_merged_all = df_results.merge(df_data[['adjusted_P_max', 'mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "#lose some data from full_adjusted_df near end since the df_data doesn't have full last day\n",
    "\n",
    "#check for missing values (NaN) in adjusted_P_max\n",
    "if df_merged_all['adjusted_P_max'].isna().any():\n",
    "    print(\"Warning: Some values are missing in the normalization profile.\")\n",
    "    \n",
    "# currently cut of a part that goes infinite\n",
    "\n",
    "#df_merged_all = df_merged_all[(df_merged_all[\"predicted_mean\"] > 0) & (df_merged_all[\"predicted_mean\"] < 5)]\n",
    "\n",
    "#denormalize the 'mean_actualPowerTot_W_inverter' column by multiplying by the 'adjusted_P_max' column\n",
    "df_merged_all['denormalized_q05'] = df_merged_all['q05'] * df_merged_all['adjusted_P_max']\n",
    "df_merged_all['denormalized_q50'] = df_merged_all['q50'] * df_merged_all['adjusted_P_max']\n",
    "df_merged_all['denormalized_q95'] = df_merged_all['q95'] * df_merged_all['adjusted_P_max']\n",
    "\n",
    "\n",
    "df_merged_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee4ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_benchmark(\"uncertainty quantile 1 timestep\", df_merged_all['mean_actualPowerTot_W_inverter'] ,df_merged_all[\"denormalized_q50\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c1f7d",
   "metadata": {},
   "source": [
    "# quantile testing on every testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d533d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute evaluation metrics\n",
    "def evaluate_benchmark2(y_true, y_pred):\n",
    "    \"\"\"Computes MAE, RMSE, MAPE, and R² and stores in a dictionary.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    #avoid zero division in MAPE\n",
    "    valid_mask = y_true != 0  \n",
    "    mape = np.mean(np.abs((y_true[valid_mask] - y_pred[valid_mask]) / y_true[valid_mask])) * 100  \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    #relative mae\n",
    "    avg = np.mean(y_true[valid_mask])\n",
    "    rel_mae = mae/avg\n",
    "    rel_rmse = rmse/avg\n",
    "\n",
    "    results = {\n",
    "        \"MAPE\": round(mape, 2),\n",
    "        \"R²\": round(r2, 4),\n",
    "        \"MAE\": round(mae, 4),\n",
    "        \"RMSE\": round(rmse, 4),\n",
    "        \"rel_MAE\": round(rel_mae, 4),\n",
    "        \"rel_RMSE\": round(rel_rmse, 4),\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d39bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set the number of hours to predict ahead\n",
    "prediction_horizon = 24  #number of hours to predict ahead\n",
    "\n",
    "#initialize lists to store predictions for the whole test set\n",
    "all_predictions_recursive = []\n",
    "all_predictions_indices = []\n",
    "\n",
    "all_predictions_q05 = []\n",
    "all_predictions_q95 = []\n",
    "\n",
    "#for the testing of every testset\n",
    "all_predictions = []\n",
    "\n",
    "#loop over the entire test set\n",
    "amount_of_times = 0\n",
    "\n",
    "steps = 8\n",
    "\n",
    "print(f\"Total number of test sets at stepsize {steps}: {len(all_test_X) // steps}\")\n",
    "\n",
    "for test_idx in range(0, len(all_test_X), steps):  #iterate over each test example\n",
    "    starting_window = all_test_X[test_idx]\n",
    "    starting_window_indeces = all_test_X_indices[test_idx]\n",
    "    #print(starting_window_indeces)\n",
    "\n",
    "    input_window = starting_window\n",
    "    input_window_indices = starting_window_indeces\n",
    "\n",
    "    predictions_recursive = []\n",
    "    predictions_indices = []\n",
    "    predictions_q05 = []\n",
    "    predictions_q95 = []\n",
    "    \n",
    "    for i in range(prediction_horizon * 4):  #total steps in 15minutes intervals\n",
    "        #predict next minute\n",
    "        num_samples = 20\n",
    "        y_pred_list = model_quantile.predict(input_window[np.newaxis, :, :])  # Returns [array_q05, array_q50, array_q95]\n",
    "\n",
    "        # Extract each quantile prediction\n",
    "        y_pred_q05 = y_pred_list[0].flatten()[0]  # 5th percentile\n",
    "        y_pred_q50 = y_pred_list[1].flatten()[0]  # 50th percentile (median)\n",
    "        y_pred_q95 = y_pred_list[2].flatten()[0]  # 95th percentile\n",
    "        \n",
    "        predictions_recursive.append(y_pred_q50)\n",
    "        predictions_q05.append(y_pred_q05)\n",
    "        predictions_q95.append(y_pred_q95)\n",
    "\n",
    "        #update time indices for predictions\n",
    "        next_index = input_window_indices[-1] + pd.Timedelta(minutes=15)\n",
    "        predictions_indices.append(next_index)\n",
    "\n",
    "        #update the input window for the next step (shift window to the left)\n",
    "        input_window = np.roll(input_window, -1, axis=0)\n",
    "        \n",
    "        #update the last element of the window with the prediction\n",
    "        input_window[-1, 0] = y_pred_q50\n",
    "        \n",
    "        #input_window[-1, 1] = next_index.day_of_week\n",
    "        #input_window[-1, 2] = next_index.month\n",
    "\n",
    "        #update hour sin and cos\n",
    "        next_hour = next_index.hour\n",
    "        #input_window[-1, 3] = np.sin(2 * np.pi * next_hour / 24)\n",
    "        #input_window[-1, 4] = np.cos(2 * np.pi * next_hour / 24)\n",
    "        \n",
    "        \n",
    "        next_day = next_index.day\n",
    "        #input_window[-1, 5] = np.sin(2 * np.pi * next_day / 365)\n",
    "        #input_window[-1, 6] = np.cos(2 * np.pi * next_day / 365)\n",
    "        \n",
    "        next_minute = next_index.minute\n",
    "        #input_window[-1, 7] = np.sin(2 * np.pi * next_minute / 60)\n",
    "        #input_window[-1, 8] = np.cos(2 * np.pi * next_minute / 60)\n",
    "        \n",
    "        \n",
    "        ##################################################\n",
    "        #test future data as direct insert in weather\n",
    "        \n",
    "        \n",
    "        #add the other features from the previous day\n",
    "        next_index_previous_day = next_index - pd.Timedelta(days=1)\n",
    "        \n",
    "        #for daylight savings, timestamps not present\n",
    "        # Check if the exact timestamp exists in the index\n",
    "        if next_index_previous_day in df_data.index:\n",
    "            data_next_day = df_data.loc[next_index_previous_day]\n",
    "        else:\n",
    "            #make next_index_previous_day also timezone aware\n",
    "            next_index_previous_day = next_index_previous_day.tz_localize(df_data.index.tzinfo)\n",
    "            # If not, get the next closest available timestamp (forward direction)\n",
    "            closest_timestamp_idx = df_data.index.searchsorted(next_index_previous_day, side='right')\n",
    "            closest_timestamp = df_data.index[closest_timestamp_idx] if closest_timestamp_idx < len(df_data) else df_data.index[-1]\n",
    "\n",
    "            data_next_day = df_data.loc[closest_timestamp]\n",
    "        \n",
    "        #if next_index in df_data.index:\n",
    "        #    data_next_day = df_data.loc[next_index]\n",
    "        #else:\n",
    "        #    next_index = next_index.tz_localize(df_data.index.tzinfo)\n",
    "        #    closest_timestamp_idx = df_data.index.searchsorted(next_index, side='right')\n",
    "        #    closest_timestamp = df_data.index[closest_timestamp_idx] if closest_timestamp_idx < len(df_data) else df_data.index[-1]\n",
    "\n",
    "        #    data_next_day = df_data.loc[closest_timestamp]\n",
    "            \n",
    "        \n",
    "        #######################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        if isinstance(data_next_day, pd.Series):\n",
    "            data_next_day = data_next_day.to_frame().T\n",
    "            \n",
    "        try:\n",
    "            input_window[-1, 1] = data_next_day.iloc[0][\"temp_dry_shelter_avg\"]\n",
    "            input_window[-1, 2] = data_next_day.iloc[0][\"normalized_value_shift_24\"]\n",
    "            input_window[-1, 3] = data_next_day.iloc[0][\"diffuseIrradiance_Wpm2\"]\n",
    "            input_window[-1, 4] = data_next_day.iloc[0][\"directNormalIrradiance_Wpm2\"]\n",
    "            input_window[-1, 5] = data_next_day.iloc[0][\"globalHorizontalIrradiance_Wpm2\"]\n",
    "            \n",
    "            #input_window[-1, 14] = data_next_day.iloc[0][\"precip_quantity\"]\n",
    "            #input_window[-1, 15] = data_next_day.iloc[0][\"temp_soil_avg\"]\n",
    "            #input_window[-1, 16] = data_next_day.iloc[0][\"wind_direction\"]\n",
    "            #input_window[-1, 17] = data_next_day.iloc[0][\"wind_gusts_speed\"]\n",
    "            #input_window[-1, 18] = data_next_day.iloc[0][\"humidity_rel_shelter_avg\"]\n",
    "            #input_window[-1, 19] = data_next_day.iloc[0][\"pressure\"]\n",
    "            #input_window[-1, 20] = data_next_day.iloc[0][\"sun_duration\"]\n",
    "            #input_window[-1, 21] = data_next_day.iloc[0][\"short_wave_from_sky_avg\"]\n",
    "            #input_window[-1, 22] = data_next_day.iloc[0][\"sun_int_avg\"]\n",
    "            #input_window[-1, 23] = data_next_day.iloc[0][\"wind_speed\"]\n",
    "            \n",
    "            #input_window[-1, 24] = data_next_day.iloc[0][\"precip_quantity_future\"]\n",
    "            #input_window[-1, 25] = data_next_day.iloc[0][\"temp_soil_avg_future\"]\n",
    "            #input_window[-1, 26] = data_next_day.iloc[0][\"wind_direction_future\"]\n",
    "            #input_window[-1, 27] = data_next_day.iloc[0][\"wind_gusts_speed_future\"]\n",
    "            #input_window[-1, 28] = data_next_day.iloc[0][\"humidity_rel_shelter_avg_future\"]\n",
    "            #input_window[-1, 29] = data_next_day.iloc[0][\"pressure_future\"]\n",
    "            #input_window[-1, 30] = data_next_day.iloc[0][\"sun_duration_future\"]\n",
    "            #input_window[-1, 31] = data_next_day.iloc[0][\"short_wave_from_sky_avg_future\"]\n",
    "            #input_window[-1, 32] = data_next_day.iloc[0][\"sun_int_avg_future\"]\n",
    "            #input_window[-1, 33] = data_next_day.iloc[0][\"wind_speed_future\"]\n",
    "            \n",
    "            \n",
    "        except KeyError:\n",
    "            input_window[-1, 1] = np.nan\n",
    "            input_window[-1, 2] = np.nan\n",
    "            input_window[-1, 3] = np.nan\n",
    "            input_window[-1, 4] = np.nan\n",
    "            input_window[-1, 5] = np.nan\n",
    "            \n",
    "            #input_window[-1, 14] = np.nan\n",
    "            #input_window[-1, 15] = np.nan\n",
    "            #input_window[-1, 16] = np.nan\n",
    "            #input_window[-1, 17] = np.nan\n",
    "            #input_window[-1, 18] = np.nan\n",
    "            #input_window[-1, 19] = np.nan\n",
    "            #input_window[-1, 20] = np.nan\n",
    "            #input_window[-1, 21] = np.nan\n",
    "            #input_window[-1, 22] = np.nan\n",
    "            #input_window[-1, 23] = np.nan\n",
    "            \n",
    "            #input_window[-1, 24] = np.nan\n",
    "            #input_window[-1, 25] = np.nan\n",
    "            #input_window[-1, 26] = np.nan\n",
    "            #input_window[-1, 27] = np.nan\n",
    "            #input_window[-1, 28] = np.nan\n",
    "            #input_window[-1, 29] = np.nan\n",
    "            #input_window[-1, 30] = np.nan\n",
    "            #input_window[-1, 31] = np.nan\n",
    "            #input_window[-1, 32] = np.nan\n",
    "            #input_window[-1, 33] = np.nan\n",
    "\n",
    "        #update indices\n",
    "        input_window_indices = np.roll(input_window_indices, -1, axis=0)\n",
    "        input_window_indices[-1] = next_index\n",
    "\n",
    "        # print progress for every 100 steps or at the last step\n",
    "        if i % 10 == 0 or i == prediction_horizon * 4 - 1:\n",
    "            print(f\"Prediction progress for test set {test_idx//steps + 1}: Step {i + 1} / {prediction_horizon * 4} ({(i + 1) / (prediction_horizon * 4) * 100:.2f}%)\")\n",
    "\n",
    "        \n",
    "    #convert predictions and indices to numpy arrays\n",
    "    predictions_recursive = np.array(predictions_recursive)\n",
    "    predictions_indices = np.array(predictions_indices)\n",
    "\n",
    "    #store predictions for this test example\n",
    "    all_predictions_recursive.append(predictions_recursive)\n",
    "    all_predictions_indices.append(predictions_indices)\n",
    "    all_predictions_q95.append(predictions_q95)\n",
    "    all_predictions_q05.append(predictions_q05)\n",
    "    \n",
    "    \n",
    "    #for the every testset code\n",
    "    df_result = pd.DataFrame({\n",
    "        \"q05\": predictions_q05,\n",
    "        \"q50\": predictions_recursive,\n",
    "        \"q95\": predictions_q95,\n",
    "    }, index = pd.Index(predictions_indices.reshape(-1), name = \"timestamp\"))\n",
    "    \n",
    "    all_predictions.append(df_result)\n",
    "\n",
    "    amount_of_times += 1\n",
    "    \n",
    "    if(amount_of_times >= 1000):\n",
    "        break\n",
    "    \n",
    "#convert all predictions to arrays for easier handling\n",
    "all_predictions_recursive = np.array(all_predictions_recursive)\n",
    "all_predictions_indices = np.array(all_predictions_indices)\n",
    "all_predictions_q95 = np.array(all_predictions_q95)\n",
    "all_predictions_q05 = np.array(all_predictions_q05)\n",
    "\n",
    "print(\"Prediction completed for all test samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f06ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_predictions.copy()\n",
    "\n",
    "for i, df in enumerate(test):\n",
    "    timezone = df_data.index.tz  #get timezone from df_data\n",
    "    df.index = df.index.tz_localize(timezone) if df.index.tz is None else df.index.tz_convert(timezone)\n",
    "    \n",
    "    df_merged_all = []\n",
    "    #merge the two DataFrames on the 'time' index\n",
    "    df_merged_all = df.merge(df_data[['adjusted_P_max', 'mean_actualPowerTot_W_inverter']], left_index=True, right_index=True, how='left')\n",
    "    #check for missing values (NaN) in adjusted_P_max\n",
    "    if df_merged_all['adjusted_P_max'].isna().any():\n",
    "        print(\"Warning: Some values are missing in the normalization profile.\")\n",
    "\n",
    "    df_merged_all = df_merged_all.dropna(subset=['adjusted_P_max'])\n",
    "    \n",
    "    #denormalize the predicted values columns by multiplying by the 'adjusted_P_max' column\n",
    "    df_merged_all['denormalized_q50'] = df_merged_all['q50'] * df_merged_all['adjusted_P_max']\n",
    "    df_merged_all['denormalized_q05'] = df_merged_all['q05'] * df_merged_all['adjusted_P_max']\n",
    "    df_merged_all['denormalized_q95'] = df_merged_all['q95'] * df_merged_all['adjusted_P_max']\n",
    "\n",
    "    test[i] = df_merged_all\n",
    "    \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = df_merged_all[df_merged_all['adjusted_P_max'].isna()]\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for df in test:\n",
    "    result = evaluate_benchmark2(df['mean_actualPowerTot_W_inverter'], df['denormalized_q50'])\n",
    "    \n",
    "    within_interval = ((df['mean_actualPowerTot_W_inverter'] >= df['denormalized_q05']) &\n",
    "                   (df['mean_actualPowerTot_W_inverter'] <= df['denormalized_q95']))\n",
    "    CP = within_interval.mean()\n",
    "\n",
    "    interval_width = df['denormalized_q95'] - df['denormalized_q05']\n",
    "    MIW = interval_width.mean()\n",
    "    relative_interval_width = interval_width / df['mean_actualPowerTot_W_inverter']\n",
    "    rMIW = relative_interval_width.mean()\n",
    "    \n",
    "    if np.isinf(rMIW):\n",
    "        rMIW = np.nan\n",
    "    \n",
    "    result[\"CP\"] = CP\n",
    "    result[\"MIW\"] = MIW\n",
    "    result[\"rMIW\"] = rMIW\n",
    "    \n",
    "    all_results.append(result)\n",
    "        \n",
    "\n",
    "#remove results with 'nan' values for any of the metrics\n",
    "filtered_results = [r for r in all_results if not any(pd.isna(v) for v in r.values())]\n",
    "\n",
    "#compute average metrics across all DataFrames\n",
    "average_results = {\n",
    "    \"Benchmark\": \"Average Across All\",\n",
    "    \"MAPE\": round(np.mean([r[\"MAPE\"] for r in filtered_results]), 2),\n",
    "    \"R²\": round(np.mean([r[\"R²\"] for r in filtered_results]), 4),\n",
    "    \"MAE\": round(np.mean([r[\"MAE\"] for r in filtered_results]), 4),\n",
    "    \"RMSE\": round(np.mean([r[\"RMSE\"] for r in filtered_results]), 4),\n",
    "    \"CP\": round(np.mean([r[\"CP\"] for r in filtered_results]), 4),\n",
    "    \"MIW\": round(np.mean([r[\"MIW\"] for r in filtered_results]), 4),\n",
    "    \"rMIW\": round(np.mean([r[\"rMIW\"] for r in filtered_results]), 4),\n",
    "    \"rel_MAE\": round(np.mean([r[\"rel_MAE\"] for r in filtered_results]), 4),\n",
    "    \"rel_RMSE\": round(np.mean([r[\"rel_RMSE\"] for r in filtered_results]), 4),\n",
    "}\n",
    "\n",
    "#print all individual results and the average\n",
    "for i, res in enumerate(filtered_results):\n",
    "    print(f\"Results for DataFrame {i+1}: {res}\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Final Average Results:\", average_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40890c85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe = test[165]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['denormalized_q50'], mode='lines', name='predicted'))\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['mean_actualPowerTot_W_inverter'], mode='lines', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['denormalized_q05'], mode='lines', name='q05',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# Upper quantile (q95) - fill between q05 and q95\n",
    "fig.add_trace(go.Scatter(x=dataframe.index, y=dataframe['denormalized_q95'],mode='lines',name='90% Interval',\n",
    "    line=dict(color='rgba(0,0,255,0)'),\n",
    "    fill='tonexty',  # fill between this trace and the previous (q05)\n",
    "    fillcolor='rgba(0,0,255,0.2)'\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title='denormalised',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Mean Actual Power (W)',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6172c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test other metrics\n",
    "within_interval = ((dataframe['mean_actualPowerTot_W_inverter'] >= dataframe['denormalized_q05']) &\n",
    "                   (dataframe['mean_actualPowerTot_W_inverter'] <= dataframe['denormalized_q95']))\n",
    "CP = within_interval.mean()\n",
    "\n",
    "interval_width = dataframe['denormalized_q95'] - dataframe['denormalized_q05']\n",
    "MIW = interval_width.mean()\n",
    "\n",
    "print(\"CP: \", CP, \" MIW: \", MIW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aea8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter rows where actual power is greater than 0\n",
    "filtered_df = dataframe[dataframe['mean_actualPowerTot_W_inverter'] > 0]\n",
    "\n",
    "#calculate CP and MIW on filtered DataFrame\n",
    "within_interval = ((filtered_df['mean_actualPowerTot_W_inverter'] >= filtered_df['denormalized_q05']) &\n",
    "                   (filtered_df['mean_actualPowerTot_W_inverter'] <= filtered_df['denormalized_q95']))\n",
    "CP = within_interval.mean()\n",
    "\n",
    "interval_width = filtered_df['denormalized_q95'] - filtered_df['denormalized_q05']\n",
    "MIW = interval_width.mean()\n",
    "relative_interval_width = interval_width / filtered_df['mean_actualPowerTot_W_inverter']\n",
    "rMIW = relative_interval_width.mean()\n",
    "\n",
    "\n",
    "print(\"filtered CP: \", CP, \"filtered MIW: \", MIW, \"filtered rMIW: \", rMIW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28f306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b9446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize list of DataFrames for each time step (96 DataFrames for 96 time steps)\n",
    "time_step_dfs = {i: pd.DataFrame(columns=['actual', 'predicted']) for i in range(output_steps*96)}\n",
    "\n",
    "#loop over each DataFrame in the test dataset and populate the 96 DataFrames\n",
    "for df in test:\n",
    "    #get the 'actual' and 'predicted' values from the DataFrame\n",
    "    actual_values = df['mean_actualPowerTot_W_inverter'].values\n",
    "    predicted_values = df['denormalized_q50'].values\n",
    "\n",
    "    #populate the DataFrames corresponding to each time step\n",
    "    for i in range(output_steps*96):  #we have 96 time steps (from 0 to 95)\n",
    "        #create a temporary dataFrame to hold the current actual and predicted values\n",
    "        temp_df = pd.DataFrame({'actual': [actual_values[i] if i < len(actual_values) else np.nan],\n",
    "                                'predicted': [predicted_values[i] if i < len(predicted_values) else np.nan]})\n",
    "        \n",
    "        time_step_dfs[i] = pd.concat([time_step_dfs[i], temp_df], ignore_index=True)\n",
    "\n",
    "#evaluate each DataFrame individually using the evaluate_benchmark2 function\n",
    "all_results = []\n",
    "\n",
    "for i in range(output_steps*96):\n",
    "    #get the actual and predicted values for the current time step DataFrame\n",
    "    step_df = time_step_dfs[i]\n",
    "\n",
    "    #drop any rows with NaN values\n",
    "    step_df = step_df.dropna()\n",
    "\n",
    "    result = evaluate_benchmark2(step_df['actual'], step_df['predicted'])\n",
    "    result[\"Time Step\"] = i\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "#compute the average results across all time steps\n",
    "average_results = {\n",
    "    \"MAPE\": round(np.mean([r[\"MAPE\"] for r in all_results]), 2),\n",
    "    \"R²\": round(np.mean([r[\"R²\"] for r in all_results]), 4),\n",
    "    \"MAE\": round(np.mean([r[\"MAE\"] for r in all_results]), 4),\n",
    "    \"RMSE\": round(np.mean([r[\"RMSE\"] for r in all_results]), 4),\n",
    "}\n",
    "\n",
    "for res in all_results:\n",
    "    print(f\"Results for Time Step {res['Time Step']}: {res}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"Final Average Results:\", average_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0b7b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#extract the metrics for plotting\n",
    "time_steps = [r[\"Time Step\"] for r in all_results]\n",
    "mape_values = [r[\"MAPE\"] for r in all_results]\n",
    "mae_values = [r[\"MAE\"] for r in all_results]\n",
    "rmse_values = [r[\"RMSE\"] for r in all_results]\n",
    "r2_values = [r[\"R²\"] for r in all_results]\n",
    "\n",
    "#create subplots\n",
    "fig = go.Figure()\n",
    "\n",
    "#plot MAPE\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=mape_values, mode='lines', name='MAPE', line=dict(color='blue')))\n",
    "\n",
    "#plot MAE\n",
    "fig.add_trace(go.Scatter(x=time_steps, y=mae_values, mode='lines', name='MAE', line=dict(color='green')))\n",
    "\n",
    "#plot RMSE\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=rmse_values, mode='lines', name='RMSE', line=dict(color='red')))\n",
    "\n",
    "#plot R²\n",
    "#fig.add_trace(go.Scatter(x=time_steps, y=r2_values, mode='lines', name='R²', line=dict(color='orange')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Evaluation Metrics Across Time Steps for MAE\",\n",
    "    xaxis_title=\"Time Step\",\n",
    "    yaxis_title=\"MAE Value (W)\",\n",
    "    legend_title=\"Metrics\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b090a2",
   "metadata": {},
   "source": [
    "file_path = r\"C:\\Users\\samr0\\OneDrive - KU Leuven\\Documents\\!School\\master\\Thesis\\data\\timestep_results_quantile_recursive_test4.csv\"\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb01e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
